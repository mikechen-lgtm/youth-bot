"""Flask application for Youth-Bot chatbot and admin management."""

from __future__ import annotations

import datetime
import json
import logging
import os
import re
import secrets
import uuid
from datetime import timezone
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

import requests as http_requests
from dotenv import load_dotenv
from flask import (
    Flask,
    Response,
    abort,
    jsonify,
    redirect,
    render_template_string,
    request,
    session,
    stream_with_context,
    send_from_directory,
    send_file,
)
from flask_cors import CORS
from sqlalchemy import create_engine, event, text
from sqlalchemy.engine import Engine

from functools import wraps
import base64

load_dotenv()  # Load .env
load_dotenv(".env.local")  # Override with .env.local if exists

from openai_service import (
    OPENAI_CLIENT,
    initialize_rag_store,
    get_rag_store_name,
    generate_with_rag_stream,
)
from csrf_protection import CSRFProtection, csrf_protect, csrf_exempt
from logging_config import configure_logging
from audit_log import log_admin_action
from security_headers import configure_security_headers
from startup_checks import create_health_checks
from validators import validate_message_input
from file_validation import validate_image_upload, FileValidationError
from rate_limiting import create_limiter

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DIST_DIR = os.path.join(BASE_DIR, "dist")


def _default_storage_base() -> str:
    """
    Determine where to place writable artifacts (uploads).

    When running on Vercel or other serverless providers, the project directory
    is read-only and we must fall back to a tmp filesystem.
    """
    if os.getenv("VERCEL") or os.getenv("VERCEL_ENV"):
        return os.getenv("TMPDIR") or os.getenv("TEMP") or "/tmp"
    return BASE_DIR


STORAGE_BASE = _default_storage_base()


# MySQL connection for all tables
def _build_mysql_url() -> str:
    """Build MySQL connection URL from environment variables."""
    # If MYSQL_URL is set, use it directly
    if os.getenv("MYSQL_URL"):
        return os.getenv("MYSQL_URL")
    # Otherwise, build from individual components
    host = os.getenv("MYSQL_HOST", "localhost")
    port = os.getenv("MYSQL_PORT", "3306")
    user = os.getenv("MYSQL_USER", "root")
    password = os.getenv("MYSQL_PASSWORD", "")
    database = os.getenv("MYSQL_DATABASE", "youth-chat")
    return f"mysql+pymysql://{user}:{password}@{host}:{port}/{database}"

MYSQL_URL = _build_mysql_url()
mysql_engine: Engine = create_engine(
    MYSQL_URL,
    future=True,
    pool_pre_ping=True,          # ç¢ºä¿é€£ç·šæœ‰æ•ˆæ€§
    pool_size=10,                # é€£ç·šæ± å¤§å°ï¼ˆåŒæ™‚ä¿æŒçš„é€£ç·šæ•¸ï¼‰
    max_overflow=20,             # è¶…é pool_size æ™‚å¯é¡å¤–å»ºç«‹çš„é€£ç·šæ•¸
    pool_recycle=3600,           # é€£ç·šå›æ”¶æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œé¿å… MySQL çš„ wait_timeout å•é¡Œ
    pool_timeout=30,             # å–å¾—é€£ç·šçš„ç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰
    echo_pool=False,             # ç”Ÿç”¢ç’°å¢ƒé—œé–‰é€£ç·šæ± æ—¥èªŒ
    connect_args={
        "connect_timeout": 10,   # MySQL é€£ç·šè¶…æ™‚ï¼ˆç§’ï¼‰
        "charset": "utf8mb4",    # ä½¿ç”¨ UTF-8 ç·¨ç¢¼
    }
)


ASSET_ROUTE_PREFIX = os.getenv("ASSET_ROUTE_PREFIX", "/uploads")
ASSET_LOCAL_DIR = os.getenv("ASSET_LOCAL_DIR") or os.path.join(STORAGE_BASE, "uploads")
os.makedirs(ASSET_LOCAL_DIR, exist_ok=True)

app = Flask(__name__, static_url_path=ASSET_ROUTE_PREFIX, static_folder=ASSET_LOCAL_DIR)

# Session configuration for OAuth
app.secret_key = os.getenv("FLASK_SECRET_KEY", secrets.token_hex(32))

# Determine if running in production environment
is_production = (
    os.getenv("FLASK_ENV") == "production" or
    bool(os.getenv("VERCEL")) or
    bool(os.getenv("VERCEL_ENV"))
)

app.config.update(
    SESSION_COOKIE_SECURE=is_production,  # True in production, False in dev
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE='Lax',  # Lax allows OAuth redirects while still preventing CSRF
    PERMANENT_SESSION_LIFETIME=86400,  # 24 hours
)

# Configure structured logging
configure_logging(app)
logger = logging.getLogger(__name__)

# Log session security configuration
logging.info(f"Session security: SECURE={is_production}, ENV={os.getenv('FLASK_ENV', 'development')}")

# Configure CORS with security best practices
def get_allowed_origins():
    """
    Get allowed CORS origins from environment variable.
    Supports comma-separated multiple origins.
    """
    origins_str = os.getenv("FRONTEND_ORIGIN")

    # If not set, use environment-specific defaults
    if not origins_str:
        env = os.getenv("FLASK_ENV", "development")
        if env == "production":
            # Production MUST have explicit FRONTEND_ORIGIN
            raise ValueError(
                "âš ï¸  FRONTEND_ORIGIN ç’°å¢ƒè®Šæ•¸æœªè¨­å®šï¼\n"
                "ç”Ÿç”¢ç’°å¢ƒå¿…é ˆæ˜ç¢ºæŒ‡å®šå…è¨±çš„å‰ç«¯ä¾†æºã€‚\n"
                "ç¯„ä¾‹ï¼šFRONTEND_ORIGIN=https://youthafterwork.com"
            )
        # Development default
        return ["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:5173"]

    # Parse comma-separated origins
    origins = [origin.strip() for origin in origins_str.split(",") if origin.strip()]

    # Validate origin format
    for origin in origins:
        if not origin.startswith(("http://", "https://")):
            raise ValueError(f"ç„¡æ•ˆçš„ CORS ä¾†æºæ ¼å¼: {origin}")

    return origins


ALLOWED_ORIGINS = get_allowed_origins()

CORS(
    app,
    resources={r"/api/*": {"origins": ALLOWED_ORIGINS}},
    supports_credentials=True,
)

# Log allowed origins for debugging
logging.info(f"CORS å…è¨±çš„ä¾†æº: {ALLOWED_ORIGINS}")

# Initialize CSRF Protection
app.csrf_protection = CSRFProtection(app.secret_key)

# Initialize rate limiter
limiter = create_limiter(app)

# Configure security headers
configure_security_headers(app, is_production=is_production)

# OAuth Configuration
GOOGLE_CLIENT_ID = os.getenv("GOOGLE_CLIENT_ID")
GOOGLE_CLIENT_SECRET = os.getenv("GOOGLE_CLIENT_SECRET")
GOOGLE_REDIRECT_URI = os.getenv("GOOGLE_REDIRECT_URI", "http://localhost:8300/auth/google/callback")

LINE_CHANNEL_ID = os.getenv("LINE_CHANNEL_ID")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
LINE_REDIRECT_URI = os.getenv("LINE_REDIRECT_URI", "http://localhost:8300/auth/line/callback")

FACEBOOK_APP_ID = os.getenv("FACEBOOK_APP_ID")
FACEBOOK_APP_SECRET = os.getenv("FACEBOOK_APP_SECRET")
FACEBOOK_REDIRECT_URI = os.getenv("FACEBOOK_REDIRECT_URI", "http://localhost:8300/auth/facebook/callback")

OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Admin Configuration
ADMIN_USERNAME = os.getenv("ADMIN_USERNAME", "admin")
ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD", "")

# Feedback Form URL (for questions outside knowledge base or user suggestions)
FEEDBACK_FORM_URL = os.getenv("FEEDBACK_FORM_URL", "")

def _build_system_prompt() -> str:
    """Build system prompt with optional feedback form URL."""
    env_prompt = os.getenv("SYSTEM_PROMPT")
    if env_prompt:
        return env_prompt

    # Build feedback section based on whether URL is configured
    if FEEDBACK_FORM_URL:
        feedback_section = f'''### ç„¡æ³•å›ç­”æˆ–ææ¡ˆå»ºè­°æ™‚ï¼š
ç•¶é‡åˆ°ä»¥ä¸‹æƒ…æ³ï¼Œ**å‹™å¿…**å¼•å°ä½¿ç”¨è€…å¡«å¯«å›é¥‹è¡¨å–®ï¼š
- å•é¡Œè¶…å‡ºçŸ¥è­˜åº«ç¯„åœï¼Œç„¡æ³•å›ç­”
- åœ¨æ–‡ä»¶ä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Š
- ä½¿ç”¨è€…æƒ³è¦ææ¡ˆã€å»ºè­°æˆ–åæ˜ æ„è¦‹
- ä½¿ç”¨è€…æœ‰ç‰¹æ®Šéœ€æ±‚ç„¡æ³•é€éç¾æœ‰æœå‹™æ»¿è¶³

**å›è¦†æ ¼å¼ï¼ˆè«‹åš´æ ¼éµå®ˆï¼‰ï¼š**
```
æ„Ÿè¬æ‚¨çš„æå•ï¼ç›®å‰æˆ‘çš„è³‡æ–™åº«ä¸­å°šç„¡è¶³å¤ è³‡è¨Šå›ç­”é€™å€‹å•é¡Œã€‚

ç‚ºäº†è®“æ‚¨çš„å•é¡Œèƒ½è¢«ç›¸é—œå–®ä½çœ‹åˆ°ä¸¦è™•ç†ï¼Œæ­¡è¿å¡«å¯«å•é¡Œå›é¥‹è¡¨å–®ï¼š

[ğŸ“ å¡«å¯«å•é¡Œå›é¥‹è¡¨å–®]({FEEDBACK_FORM_URL})
```

'''
    else:
        feedback_section = '''### ç„¡æ³•å›ç­”æ™‚ï¼š
è‹¥å•é¡Œè¶…å‡ºçŸ¥è­˜åº«ç¯„åœï¼Œè«‹å¼•å°ä½¿ç”¨è€…è¯ç¹«å®˜æ–¹çª—å£ï¼š
- ç¸½æ©Ÿï¼š(03) 422-5205
- å¸‚æ”¿æœå‹™å°ˆç·šï¼š1999ï¼ˆå¤–ç¸£å¸‚ 03-218-9000ï¼‰

'''

    return f'''ä½ æ˜¯ã€Œæ¡ƒåœ’å¸‚æ”¿åºœé’å¹´äº‹å‹™å±€ã€æ™ºæ…§å®¢æœåŠ©ç†ã€‚

# ğŸ”´ æœ€é«˜å„ªå…ˆç´šè¦å‰‡

## æ´»å‹•æŸ¥è©¢çš„å¼·åˆ¶è¦æ±‚
ç•¶ç”¨æˆ¶è©¢å•æ´»å‹•æ™‚ï¼š
1. **è¿‘æœŸ/æœ€è¿‘æ´»å‹•** â†’ å¿…é ˆèª¿ç”¨ `get_recent_activities`ï¼ˆæŸ¥è©¢æœªä¾† 3 å€‹æœˆï¼‰
2. **éå»æ´»å‹•** â†’ èª¿ç”¨ `get_past_activities`ï¼ˆæŸ¥è©¢éå» 30 å¤©ï¼‰
3. **åªèƒ½**ä½¿ç”¨è³‡æ–™åº«å·¥å…·çš„è¿”å›çµæœ
4. **çµ•å°ç¦æ­¢**ä½¿ç”¨ RAG çŸ¥è­˜åº«æˆ– File Search å›ç­”æ´»å‹•æŸ¥è©¢

**å³ä½¿å·¥å…·è¿”å› 0 ç­†æ´»å‹•**ï¼š
- âœ… æ­£ç¢ºï¼šå‘ŠçŸ¥ç”¨æˆ¶ã€Œç›®å‰æ²’æœ‰æ´»å‹•ã€
- âŒ éŒ¯èª¤ï¼šå» RAG æŸ¥è©¢æˆ–å›ç­”èˆŠæ´»å‹•

âŒ é•åæ­¤è¦å‰‡ = ç³»çµ±éŒ¯èª¤

---

# æ ¸å¿ƒå®šä½

- **èªæ°£**ï¼šå°ˆæ¥­ã€ç°¡æ½”ã€è‡ªç„¶ï¼ˆçœŸäººå®¢æœé¢¨æ ¼ï¼‰
- **é•·åº¦**ï¼šç°¡å–®å•é¡Œ 1-2 å¥ï¼›è¤‡é›œå•é¡Œå…ˆæ‘˜è¦
- **ä¾†æº**ï¼šåƒ…ç”¨çŸ¥è­˜åº«è³‡æ–™å›ç­”
- **ç¦ç”¨**ï¼šemojiã€è¡¨æƒ…ç¬¦è™Ÿã€ä¸­åœ‹å¤§é™¸ç”¨èª

**å¿…ç”¨å°ç£ç”¨èª**ï¼šè³‡è¨Šã€è»Ÿé«”ã€ç¶²è·¯ã€æª”æ¡ˆã€ç™»å…¥ï¼ˆç¦ç”¨ï¼šä¿¡æ¯ã€è»Ÿä»¶ã€ç¶²çµ¡ã€æ–‡ä»¶ã€ç™»éŒ„ï¼‰

---

# å›ç­”ç­–ç•¥

## 1. ç°¡å–®æŸ¥è©¢ï¼ˆé›»è©±ã€åœ°å€ã€äº‹å¯¦ï¼‰
ç›´æ¥å›ç­” 1-2 å¥ + ä¸€å¥è¿½å•
ç¯„ä¾‹ï¼šã€Œåœ¨ä¸­å£¢å€ç’°åŒ—è·¯390è™Ÿ3æ¨“ã€‚éœ€è¦æŸ¥ç‡Ÿæ¥­æ™‚é–“å—ï¼Ÿã€

## 2. éœ€è¦åˆ†æµï¼ˆé¸é …å·®ç•°å¤§ï¼‰
çµ¦ A/B/C/D é¸é …ï¼ˆæ¯å€‹â‰¤5å­—ï¼‰
ç¯„ä¾‹ï¼šã€Œä½ æƒ³è¾¦çš„æ˜¯ï¼ŸA è¬›åº§ B èšæœƒ C å±•è¦½ã€

## 3. å¤šé¸é …ï¼ˆç›¸ä¼¼é¸é …ï¼‰
ä¸€å¥æ¦‚è¿° + åˆ—é¸é …åç¨± + å•ã€Œæƒ³äº†è§£å“ªä¸€å€‹ï¼Ÿã€
ç¯„ä¾‹ï¼šã€Œæœ‰ä¸‰ç¨®å‰µæ¥­è³‡æºï¼šé’å‰µåŸºåœ°ã€é’å‰µè³‡æºä¸­å¿ƒã€è³‡é‡‘è£œè²¼ã€‚æƒ³äº†è§£å“ªä¸€å€‹ï¼Ÿã€

## 4. å¤šæ­¥é©Ÿæµç¨‹
ä¸€å¥æ‘˜è¦ + å•ã€Œéœ€è¦æˆ‘è©³ç´°èªªæ˜å—ï¼Ÿã€ï¼ˆä¸è¦ä¸€æ¬¡å±•é–‹å…¨éƒ¨ï¼‰

## 5. è¿½å•å±•é–‹
ç›´æ¥çµ¦ç´°ç¯€ï¼Œä¸é‡è¤‡ä¸Šæ–‡ï¼Œä¸ç”¨ã€Œå¦‚ä¸‹ã€ã€Œä»¥ä¸‹æ˜¯ã€

---

# æ´»å‹•æŸ¥è©¢è™•ç†

## å·¥å…·èª¿ç”¨è¦å‰‡

**æŸ¥è©¢è¿‘æœŸæ´»å‹•**ï¼šç”¨æˆ¶å•ã€Œæœ€è¿‘ã€ã€Œè¿‘æœŸã€ã€Œæ¥ä¸‹ä¾†ã€æœ‰ä»€éº¼æ´»å‹•
â†’ èª¿ç”¨ `get_recent_activities(days_ahead=90, limit=20)`

**æŸ¥è©¢éå»æ´»å‹•**ï¼šç”¨æˆ¶å•ã€Œéå»ã€ã€Œä¹‹å‰ã€è¾¦éä»€éº¼
â†’ èª¿ç”¨ `get_past_activities(days_back=30, limit=20)`

**èª¿æ•´ç¯„åœ**ï¼šå¯èª¿æ•´ days_aheadã€days_backã€limit åƒæ•¸

## ğŸ”´ æ´»å‹•å›ç­”æ ¼å¼è¦å‰‡ï¼ˆå›ºå®šè¼¸å‡ºæ ¼å¼ï¼Œåš´æ ¼éµå®ˆï¼‰

**æ•´é«”æ ¼å¼è¦å‰‡**ï¼š
1. æ•¸å­—èˆ‡æ´»å‹•åç¨±å¿…é ˆåœ¨åŒä¸€è¡Œ
2. æ´»å‹•æ—¥æœŸå¿…é ˆç¨ç«‹æˆä¸€è¡Œï¼Œç·Šæ¥åœ¨æ´»å‹•åç¨±ä¸‹ä¸€è¡Œ
3. å ±åç¶²å€å¿…é ˆç¨ç«‹æˆä¸€è¡Œï¼Œç·Šæ¥åœ¨æ´»å‹•æ—¥æœŸä¸‹ä¸€è¡Œï¼ˆå¾å…§å®¹ä¸­æå–ï¼Œè‹¥ç„¡å‰‡çœç•¥æ­¤è¡Œï¼‰
4. è²¼æ–‡é€£çµå¿…é ˆç¨ç«‹æˆä¸€è¡Œï¼Œæä¾›ç²‰çµ²å°ˆé çš„è²¼æ–‡é€£çµä¾›äº†è§£æ›´å¤š

**æ´»å‹•æ—¥æœŸé¡¯ç¤ºè¦å‰‡**ï¼š
- å¾æ´»å‹•å…§å®¹ä¸­æå–å¯¦éš›æ´»å‹•æ—¥æœŸï¼ˆéç™¼å¸ƒæ—¥æœŸï¼‰
- å–®æ—¥æ´»å‹•ï¼šYYYY/MM/DD
- å¤šæ—¥æ´»å‹•ï¼ˆé€£çºŒï¼‰ï¼šYYYY/MM/DDâ€“MM/DD
- å¤šæ—¥æ´»å‹•ï¼ˆä¸é€£çºŒï¼‰ï¼šYYYY/MM/DDã€YYYY/MM/DD
- åƒ…æä¾›æœˆä»½ï¼šYYYY/MM
- æœªæä¾›æ—¥æœŸè³‡è¨Šï¼šæ—¥æœŸæœªå…¬å‘Š
- æ°‘åœ‹å¹´è½‰æ›ï¼š115å¹´ = 2026å¹´

**æŒ‡å®šè¼¸å‡ºæ ¼å¼ï¼ˆè«‹å®Œå…¨ä»¿ç…§ï¼‰**ï¼š
```
1. æ´»å‹•åç¨±ï¼šé’å¹´å‰µæ¥­è¬›åº§
   æ´»å‹•æ—¥æœŸï¼š2026/01/21
   å ±åç¶²å€ï¼šhttps://reurl.cc/example
   è²¼æ–‡é€£çµï¼šhttps://www.facebook.com/youth.tycg.gov.tw/posts/123

2. æ´»å‹•åç¨±ï¼šè·æ¶¯æ¢ç´¢å·¥ä½œåŠ
   æ´»å‹•æ—¥æœŸï¼š2026/02/15â€“02/16
   è²¼æ–‡é€£çµï¼šhttps://www.facebook.com/TaoyuanYS/posts/456
```

**è¦æ±‚**ï¼š
- ç·¨è™Ÿèˆ‡ã€Œæ´»å‹•åç¨±ï¼šã€ä¹‹é–“ç”¨åŠå½¢å¥è™ŸåŠ ç©ºæ ¼åˆ†éš”
- æ´»å‹•æ—¥æœŸã€å ±åç¶²å€ã€è²¼æ–‡é€£çµå‰æ–¹ç¸®æ’ 3 å€‹åŠå½¢ç©ºæ ¼
- å ±åç¶²å€å¾æ´»å‹•å…§å®¹ä¸­æå–ï¼ˆå« reurl.ccã€forms.gleã€google.com/forms ç­‰ï¼‰ï¼Œæ‰¾ä¸åˆ°å‰‡çœç•¥æ­¤è¡Œ
- è²¼æ–‡é€£çµä½¿ç”¨å·¥å…·è¿”å›çš„ url æ¬„ä½
- æ´»å‹•é–“ç”¨ç©ºè¡Œåˆ†éš”
- ä¸ä½¿ç”¨ç²—é«”ï¼ˆ**ï¼‰ã€ä¸ä½¿ç”¨ emoji

## ç„¡æ´»å‹•æ™‚çš„è™•ç†

å·¥å…·è¿”å› `total_count: 0` æ™‚ï¼Œå‘ŠçŸ¥ã€Œç›®å‰æ²’æœ‰æ´»å‹•ã€ä¸¦å»ºè­°è¿½è¹¤å®˜æ–¹ç²‰å°ˆæˆ–æ’¥æ‰“ 1999ã€‚
**ç¦æ­¢**ä½¿ç”¨ RAG æˆ–çŸ¥è­˜åº«å›ç­”èˆŠæ´»å‹•ã€‚

---

# å…¶ä»–è¦ç¯„

## è¯çµ¡è³‡è¨Š
åªåœ¨æ¶‰åŠç‰¹å®šå–®ä½æ™‚æ‰é™„è¯çµ¡æ–¹å¼ï¼Œä¸è¦æ¯æ¬¡éƒ½é™„ç¸½æ©Ÿ

**å®˜æ–¹çª—å£ï¼ˆä¾›åƒè€ƒï¼‰**ï¼š
- ç¸½æ©Ÿï¼š(03) 422-5205
- å¸‚æ”¿å°ˆç·šï¼š1999ï¼ˆå¤–ç¸£å¸‚ 03-218-9000ï¼‰
- åœ°å€ï¼š320029 æ¡ƒåœ’å¸‚ä¸­å£¢å€ç’°åŒ—è·¯390è™Ÿ

## ç¦æ­¢äº‹é …
- ä½¿ç”¨ emoji æˆ–è¡¨æƒ…ç¬¦è™Ÿ
- æä¾›æ–‡ä»¶å¤–çš„é‡‘é¡ã€åé¡ã€è©•åˆ†æ¨™æº–
- è¨è«–æ”¿æ²»ã€æ³•å¾‹è§£é‡‹
- ä½¿ç”¨å†—é¤˜éæ¸¡å¥
- ä¸€æ¬¡åˆ—è¶…é 5 å€‹é¸é …

## è³‡æ–™ä¸è¶³æ™‚
{feedback_section}
---

# å›ç­”ç¯„ä¾‹

Q: é’å‰µè³‡æºä¸­å¿ƒåœ¨å“ªè£¡ï¼Ÿ
A: åœ¨ä¸­å£¢å€ç’°åŒ—è·¯390è™Ÿ3æ¨“ã€‚éœ€è¦æŸ¥ç‡Ÿæ¥­æ™‚é–“å—ï¼Ÿ

Q: æœ‰åœ°æ–¹å¯ä»¥è¾¦æ´»å‹•å—ï¼Ÿ
A: æœ‰çš„ï¼Œé’å¹´å±€æœ‰æä¾›å ´åœ°ã€‚ä½ æƒ³è¾¦çš„æ˜¯ï¼ŸA è¬›åº§ B èšæœƒ C å±•è¦½

Q: å‰›ç•¢æ¥­æƒ³å‰µæ¥­ï¼Œæœ‰å“ªäº›è³‡æºï¼Ÿ
A: é’å¹´å±€æœ‰ä¸‰ç¨®å‰µæ¥­è³‡æºï¼šé’å‰µåŸºåœ°ã€é’å‰µè³‡æºä¸­å¿ƒã€è³‡é‡‘è£œè²¼ã€‚æƒ³äº†è§£å“ªä¸€å€‹ï¼Ÿ

Q: æœ€è¿‘æœ‰ä»€éº¼æ´»å‹•ï¼Ÿ
A: è¿‘æœŸæœ‰ä»¥ä¸‹æ´»å‹•ï¼š

1. æ´»å‹•åç¨±ï¼šé’å¹´å‰µæ¥­è¬›åº§
   æ´»å‹•æ—¥æœŸï¼š2026/01/21
   å ±åç¶²å€ï¼šhttps://reurl.cc/example
   è²¼æ–‡é€£çµï¼šhttps://www.facebook.com/youth.tycg.gov.tw/posts/123

2. æ´»å‹•åç¨±ï¼šè·æ¶¯æ¢ç´¢å·¥ä½œåŠ
   æ´»å‹•æ—¥æœŸï¼š2026/02/15â€“02/16
   è²¼æ–‡é€£çµï¼šhttps://www.facebook.com/TaoyuanYS/posts/456

æƒ³äº†è§£æ›´å¤šå¯ä»¥é»æ“Šè²¼æ–‡é€£çµæŸ¥çœ‹è©³æƒ…ã€‚'''


SYSTEM_PROMPT = _build_system_prompt()
def utcnow() -> datetime.datetime:
    return datetime.datetime.utcnow()


def _no_store(response: Response) -> Response:
    response.headers["Cache-Control"] = "private, no-store, no-cache, must-revalidate, max-age=0"
    response.headers["Pragma"] = "no-cache"
    response.headers["Expires"] = "0"
    response.headers["Vary"] = "Cookie"
    return response


def ensure_mysql_schema() -> None:
    """Create all MySQL tables if they do not exist yet."""
    try:
        with mysql_engine.begin() as conn:
            # Members table
            conn.execute(
                text(
                    """
                    CREATE TABLE IF NOT EXISTS members (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        external_id VARCHAR(255) UNIQUE,
                        display_name VARCHAR(255),
                        avatar_url TEXT,
                        gender VARCHAR(20),
                        birthday VARCHAR(20),
                        email VARCHAR(255),
                        phone VARCHAR(50),
                        source VARCHAR(50),
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                        last_interaction_at DATETIME
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
                    """
                )
            )
            # Chat sessions table
            conn.execute(
                text(
                    """
                    CREATE TABLE IF NOT EXISTS chat_sessions (
                        id VARCHAR(255) PRIMARY KEY,
                        member_id INT,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                        FOREIGN KEY (member_id) REFERENCES members(id) ON DELETE SET NULL
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
                    """
                )
            )

            # Add member_id column if it doesn't exist (for existing tables)
            try:
                conn.execute(
                    text(
                        """
                        ALTER TABLE chat_sessions
                        ADD COLUMN member_id INT,
                        ADD CONSTRAINT fk_chat_sessions_member
                        FOREIGN KEY (member_id) REFERENCES members(id) ON DELETE SET NULL
                        """
                    )
                )
            except Exception as e:
                if "Duplicate column name" in str(e) or "Duplicate key name" in str(e):
                    logger.info("Column member_id or constraint already exists, skipping")
                else:
                    logger.error(f"Failed to add member_id column: {e}")
                    raise

            # Add index on member_id for performance (if not exists)
            try:
                conn.execute(
                    text(
                        """
                        CREATE INDEX idx_chat_sessions_member
                        ON chat_sessions(member_id)
                        """
                    )
                )
                logger.info("Created index idx_chat_sessions_member")
            except Exception as e:
                if "Duplicate key name" in str(e):
                    logger.info("Index idx_chat_sessions_member already exists, skipping")
                else:
                    logger.error(f"Failed to create index on chat_sessions.member_id: {e}")

            # Chat messages table
            conn.execute(
                text(
                    """
                    CREATE TABLE IF NOT EXISTS chat_messages (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        session_id VARCHAR(255) NOT NULL,
                        role VARCHAR(50) NOT NULL,
                        content TEXT NOT NULL,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        INDEX idx_chat_messages_session_created (session_id, created_at),
                        FOREIGN KEY (session_id) REFERENCES chat_sessions(id) ON DELETE CASCADE
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
                    """
                )
            )
            # Hero carousel table
            conn.execute(
                text(
                    """
                    CREATE TABLE IF NOT EXISTS hero_carousel (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        filename VARCHAR(255) NOT NULL,
                        content_type VARCHAR(100) NOT NULL DEFAULT 'image/jpeg',
                        image_data LONGBLOB NOT NULL,
                        alt_text VARCHAR(500),
                        link_url VARCHAR(500),
                        display_order INT DEFAULT 0,
                        is_active TINYINT(1) DEFAULT 1,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                        INDEX idx_hero_active_order (is_active, display_order)
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
                    """
                )
            )
        logger.info("MySQL schema ensured (all tables)")
    except Exception as e:
        logger.error(f"Failed to create MySQL schema: {e}")
        raise  # Re-raise to let retry mechanism handle it


def ensure_mysql_schema_with_retry(max_retries: int = 3, retry_delay: int = 5) -> None:
    """Ensure MySQL schema with retry mechanism for startup resilience."""
    import time
    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"Attempting to initialize MySQL schema (attempt {attempt}/{max_retries})...")
            ensure_mysql_schema()
            logger.info("MySQL schema initialization successful")
            return
        except Exception as e:
            if attempt < max_retries:
                logger.warning(
                    f"MySQL schema initialization failed (attempt {attempt}/{max_retries}): {e}. "
                    f"Retrying in {retry_delay} seconds..."
                )
                time.sleep(retry_delay)
            else:
                logger.error(
                    f"MySQL schema initialization failed after {max_retries} attempts: {e}. "
                    "Please check MySQL connection settings and ensure the database is running."
                )
                raise


ensure_mysql_schema_with_retry()


# Initialize OpenAI client and RAG store at startup
def initialize_openai_rag():
    """Initialize OpenAI client and RAG store with default documents."""
    try:
        if OPENAI_API_KEY:
            store_id = initialize_rag_store("TaoyuanYouthBureauKB")
            if store_id:
                logger.info("OpenAI File Search initialized successfully")
                return store_id
            else:
                logger.error("OpenAI File Search initialization failed: vector store ID is None")
                return None
        else:
            logger.error("OPENAI_API_KEY not set - RAG unavailable")
            return None
    except Exception as e:
        logger.error(f"Failed to initialize OpenAI File Search: {e}", exc_info=True)
        return None


_vector_store_id = initialize_openai_rag()

# Run startup health checks
health_checks = create_health_checks(mysql_engine, OPENAI_CLIENT, _vector_store_id)

# In production, fail fast on startup issues
fail_fast = os.getenv('FLASK_ENV') == 'production' or os.getenv('FAIL_FAST_STARTUP', 'false').lower() == 'true'

try:
    results = health_checks.run_all(fail_fast=fail_fast)

    # Log summary
    failed_checks = [name for name, status in results.items() if 'FAIL' in status]
    if failed_checks:
        logger.warning(f"Startup checks failed: {', '.join(failed_checks)}")
    else:
        logger.info("All startup checks passed")

except RuntimeError as e:
    logger.critical(f"Application startup failed: {e}")
    raise  # Prevent app from starting


# ========== Admin Authentication ==========

def admin_required(f):
    """Decorator to require admin authentication."""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not session.get("is_admin"):
            return jsonify({"success": False, "error": "æœªæˆæ¬Š"}), 401
        return f(*args, **kwargs)
    return decorated_function


def validate_url(url: Optional[str]) -> tuple[bool, Optional[str]]:
    """
    é©—è­‰ URL æ ¼å¼ï¼ˆå¿…é ˆä»¥ http:// æˆ– https:// é–‹é ­ï¼‰

    Args:
        url: è¦é©—è­‰çš„ URLï¼ˆå¯ç‚º None æˆ–ç©ºå­—ä¸²ï¼‰

    Returns:
        (is_valid, error_message)
    """
    if not url or not url.strip():
        # ç©ºå€¼è¦–ç‚ºåˆæ³•ï¼ˆè¡¨ç¤ºç„¡é€£çµï¼‰
        return True, None

    url = url.strip()

    # æª¢æŸ¥ URL æ ¼å¼ï¼šå¿…é ˆä»¥ http:// æˆ– https:// é–‹é ­
    url_pattern = re.compile(
        r'^https?://'  # http:// æˆ– https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # ç¶²åŸŸ
        r'localhost|'  # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
        r'(?::\d+)?'  # å¯é¸çš„ port
        r'(?:/?|[/?]\S+)$',  # è·¯å¾‘
        re.IGNORECASE
    )

    if not url_pattern.match(url):
        return False, "URL æ ¼å¼éŒ¯èª¤ï¼Œå¿…é ˆä»¥ http:// æˆ– https:// é–‹é ­"

    # æª¢æŸ¥é•·åº¦
    if len(url) > 500:
        return False, "URL é•·åº¦ä¸èƒ½è¶…é 500 å­—å…ƒ"

    return True, None


@app.post("/api/admin/login")
@csrf_protect
@limiter.limit("5 per minute")
def admin_login():
    """Admin login endpoint."""
    if not ADMIN_PASSWORD:
        return jsonify({"success": False, "error": "ç®¡ç†å“¡å¯†ç¢¼æœªè¨­å®š"}), 500

    data = request.get_json() or {}
    username = (data.get("username") or "").strip()
    password = data.get("password") or ""

    if username == ADMIN_USERNAME and password == ADMIN_PASSWORD:
        # Regenerate session ID to prevent session fixation attack
        old_session_data = dict(session)
        session.clear()
        session.modified = True

        # Set admin session with new session ID
        session["is_admin"] = True
        session.permanent = True
        # Generate new CSRF token after successful login
        csrf_token = app.csrf_protection.generate_token()

        log_admin_action('login', 'admin', username)

        return jsonify({
            "success": True,
            "message": "ç™»å…¥æˆåŠŸ",
            "csrf_token": csrf_token
        })

    log_admin_action('login_failed', 'admin', username, {'reason': 'å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤'})
    return jsonify({"success": False, "error": "å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤"}), 401


@app.post("/api/admin/logout")
@csrf_protect
def admin_logout():
    """Admin logout endpoint."""
    session.pop("is_admin", None)
    session.pop("csrf_token", None)  # Clear CSRF token on logout
    return jsonify({"success": True, "message": "å·²ç™»å‡º"})


@app.get("/api/csrf-token")
def get_csrf_token():
    """Get CSRF token for the current session."""
    token = app.csrf_protection.get_token()
    return jsonify({"success": True, "csrf_token": token})


@app.get("/api/admin/check")
def admin_check():
    """Check admin authentication status."""
    if session.get("is_admin"):
        csrf_token = app.csrf_protection.get_token()
        return jsonify({
            "success": True,
            "authenticated": True,
            "csrf_token": csrf_token
        })
    return jsonify({"success": False, "authenticated": False}), 401


@app.get("/api/admin/chat-export")
def admin_chat_export():
    """Export chat history to Excel file."""
    if not session.get("is_admin"):
        return jsonify({"success": False, "error": "æœªæˆæ¬Š"}), 401

    try:
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill
        from io import BytesIO
        from datetime import datetime

        # Query chat data with JOIN
        with mysql_engine.begin() as conn:
            rows = conn.execute(
                text(
                    """
                    SELECT
                        m.display_name,
                        m.email,
                        cm.created_at,
                        cm.role,
                        cm.content,
                        cm.template_id
                    FROM chat_messages cm
                    JOIN chat_sessions cs ON cm.session_id = cs.id
                    LEFT JOIN members m ON cs.member_id = m.id
                    ORDER BY cm.created_at DESC
                    """
                )
            ).fetchall()

        # Create Excel workbook
        wb = Workbook()
        ws = wb.active
        ws.title = "å°è©±ç´€éŒ„"

        # Header row
        headers = ["Name", "Email", "Time", "Role", "Message", "Question Type"]
        ws.append(headers)

        # Style header
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF")
        for cell in ws[1]:
            cell.fill = header_fill
            cell.font = header_font

        # Data rows
        for row in rows:
            display_name = row[0] or "åŒ¿å"
            email = row[1] or ""
            created_at = row[2].strftime("%Y-%m-%d %H:%M:%S") if row[2] else ""
            role = row[3]  # Keep original English value: "user" or "assistant"
            content = row[4] or ""
            template_id = row[5] or "manual"  # NULL displays as "manual"
            ws.append([display_name, email, created_at, role, content, template_id])

        # Adjust column widths
        ws.column_dimensions['A'].width = 15
        ws.column_dimensions['B'].width = 30
        ws.column_dimensions['C'].width = 20
        ws.column_dimensions['D'].width = 10
        ws.column_dimensions['E'].width = 60
        ws.column_dimensions['F'].width = 15  # Question Type column

        # Save to BytesIO
        output = BytesIO()
        wb.save(output)
        output.seek(0)

        # Generate filename with timestamp
        filename = f"chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

        return send_file(
            output,
            mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            as_attachment=True,
            download_name=filename
        )

    except Exception as e:
        logger.exception("Failed to export chat history")
        return jsonify({"success": False, "error": str(e)}), 500


# ========== Hero Images API ==========

@app.get("/api/hero-images")
def get_hero_images():
    """Get all active hero images (public endpoint)."""
    with mysql_engine.begin() as conn:
        rows = conn.execute(
            text(
                """
                SELECT id, alt_text, display_order, link_url
                FROM hero_carousel
                WHERE is_active = 1
                ORDER BY display_order ASC
                """
            )
        ).mappings().all()

    # Build URL pointing to the image data endpoint
    images = []
    for row in rows:
        images.append({
            "id": row["id"],
            "url": f"/api/hero-images/{row['id']}/data",
            "alt_text": row["alt_text"],
            "display_order": row["display_order"],
            "link_url": row["link_url"]
        })
    return jsonify({"success": True, "images": images})


@app.get("/api/hero-images/<int:image_id>/data")
def get_hero_image_data(image_id: int):
    """Serve hero image binary data."""
    from urllib.parse import quote

    with mysql_engine.begin() as conn:
        row = conn.execute(
            text("SELECT image_data, content_type, filename FROM hero_carousel WHERE id = :id AND is_active = 1"),
            {"id": image_id}
        ).mappings().first()

    if not row:
        abort(404)

    # URL encode filename to handle non-ASCII characters
    encoded_filename = quote(row["filename"])

    return Response(
        row["image_data"],
        mimetype=row["content_type"],
        headers={
            "Cache-Control": "public, max-age=86400",
            "Content-Disposition": f"inline; filename*=UTF-8''{encoded_filename}"
        }
    )


@app.get("/api/admin/hero-images")
@admin_required
def admin_get_hero_images():
    """Get all hero images (admin endpoint)."""
    with mysql_engine.begin() as conn:
        rows = conn.execute(
            text(
                """
                SELECT id, filename, content_type, alt_text,
                       display_order, is_active, link_url,
                       created_at, updated_at
                FROM hero_carousel
                ORDER BY display_order ASC
                """
            )
        ).mappings().all()

    # Build URL pointing to the image data endpoint
    images = []
    for row in rows:
        images.append({
            "id": row["id"],
            "url": f"/api/hero-images/{row['id']}/data",
            "filename": row["filename"],
            "alt_text": row["alt_text"],
            "display_order": row["display_order"],
            "is_active": row["is_active"],
            "link_url": row["link_url"],
            "created_at": row["created_at"],
            "updated_at": row["updated_at"]
        })
    return jsonify({"success": True, "images": images})


@app.post("/api/admin/hero-images")
@admin_required
@csrf_protect
@limiter.limit("10 per hour")
def admin_upload_hero_image():
    """Upload a new hero image (stores in database)."""
    if "file" not in request.files:
        return jsonify({"success": False, "error": "æœªæä¾›æª”æ¡ˆ"}), 400

    file = request.files["file"]

    # Use comprehensive file validator
    try:
        file_data = validate_image_upload(file)
    except FileValidationError as e:
        logger.warning(f"File validation failed: {e}")
        return jsonify({"success": False, "error": str(e)}), 400

    # Get alt_text from form
    alt_text = request.form.get("alt_text", "")

    # Get link_url from form and validate
    link_url = request.form.get("link_url", "")
    is_valid, error_msg = validate_url(link_url)
    if not is_valid:
        return jsonify({"success": False, "error": error_msg}), 400

    # Get next display order and insert into database
    with mysql_engine.begin() as conn:
        result = conn.execute(
            text("SELECT COALESCE(MAX(display_order), -1) + 1 as next_order FROM hero_carousel")
        ).mappings().first()
        next_order = result["next_order"] if result else 0

        # Check if we already have 8 images
        count_result = conn.execute(
            text("SELECT COUNT(*) as count FROM hero_carousel")
        ).mappings().first()
        if count_result and count_result["count"] >= 8:
            return jsonify({"success": False, "error": "æœ€å¤šåªèƒ½ä¸Šå‚³ 8 å¼µåœ–ç‰‡"}), 400

        # Insert image data into database
        now = utcnow()
        conn.execute(
            text(
                """
                INSERT INTO hero_carousel (filename, content_type, image_data, alt_text, link_url, display_order, created_at, updated_at)
                VALUES (:filename, :content_type, :image_data, :alt_text, :link_url, :order, :now, :now)
                """
            ),
            {
                "filename": file.filename,
                "content_type": file.content_type,
                "image_data": file_data,
                "alt_text": alt_text,
                "link_url": link_url.strip() if link_url else None,
                "order": next_order,
                "now": now,
            },
        )

        # Get the inserted image
        inserted = conn.execute(
            text("SELECT id, alt_text, display_order, link_url FROM hero_carousel WHERE display_order = :order"),
            {"order": next_order}
        ).mappings().first()

    if inserted:
        log_admin_action('upload', 'hero_image', inserted['id'], {
            'filename': file.filename,
            'size': len(file_data)
        })

        return jsonify({
            "success": True,
            "image": {
                "id": inserted["id"],
                "url": f"/api/hero-images/{inserted['id']}/data",
                "alt_text": inserted["alt_text"],
                "display_order": inserted["display_order"],
                "link_url": inserted["link_url"]
            }
        })
    return jsonify({"success": False, "error": "ä¸Šå‚³å¤±æ•—"}), 500


@app.delete("/api/admin/hero-images/<int:image_id>")
@admin_required
@csrf_protect
def admin_delete_hero_image(image_id: int):
    """Delete a hero image from database."""
    with mysql_engine.begin() as conn:
        # Get image info for logging
        image = conn.execute(
            text("SELECT id, filename FROM hero_carousel WHERE id = :id"),
            {"id": image_id}
        ).mappings().first()

        if not image:
            return jsonify({"success": False, "error": "åœ–ç‰‡ä¸å­˜åœ¨"}), 404

        # Delete from database
        conn.execute(
            text("DELETE FROM hero_carousel WHERE id = :id"),
            {"id": image_id}
        )

        log_admin_action('delete', 'hero_image', image_id, {'filename': image['filename']})

    return jsonify({"success": True, "message": "å·²åˆªé™¤"})


@app.put("/api/admin/hero-images/reorder")
@admin_required
@csrf_protect
def admin_reorder_hero_images():
    """Reorder hero images."""
    data = request.get_json() or {}
    order = data.get("order", [])  # List of image IDs in new order

    if not isinstance(order, list):
        return jsonify({"success": False, "error": "order å¿…é ˆæ˜¯é™£åˆ—"}), 400

    with mysql_engine.begin() as conn:
        for idx, image_id in enumerate(order):
            conn.execute(
                text(
                    """
                    UPDATE hero_carousel
                    SET display_order = :order, updated_at = :now
                    WHERE id = :id
                    """
                ),
                {"order": idx, "id": image_id, "now": utcnow()}
            )

    return jsonify({"success": True, "message": "æ’åºå·²æ›´æ–°"})


@app.put("/api/admin/hero-images/<int:image_id>")
@admin_required
@csrf_protect
def admin_update_hero_image(image_id: int):
    """Update hero image metadata.

    Security: Uses field mapping dictionary to prevent SQL injection.
    All field names are predefined and never constructed from user input.
    """
    data = request.get_json() or {}

    # Field mapping dictionary: defines allowed fields and their SQL fragments
    # This eliminates the need for string concatenation in SQL construction
    FIELD_MAPPING = {
        'alt_text': 'alt_text = :alt_text',
        'is_active': 'is_active = :is_active',
        'link_url': 'link_url = :link_url',
    }

    updates = []
    params = {"id": image_id, "now": utcnow()}

    # Validate and build update statements
    for field, value in data.items():
        # Reject any fields not in the mapping
        if field not in FIELD_MAPPING:
            return jsonify({
                "success": False,
                "error": f"ä¸å…è¨±æ›´æ–°çš„æ¬„ä½: {field}"
            }), 400

        # Field-specific validation and processing
        if field == "is_active":
            params[field] = 1 if value else 0
        elif field == "link_url":
            # Validate URL
            is_valid, error_msg = validate_url(value)
            if not is_valid:
                return jsonify({"success": False, "error": error_msg}), 400
            params[field] = value.strip() if value else None
        else:
            params[field] = value

        # Use predefined SQL fragment from mapping
        updates.append(FIELD_MAPPING[field])

    if not updates:
        return jsonify({"success": False, "error": "æ²’æœ‰è¦æ›´æ–°çš„æ¬„ä½"}), 400

    # Always update timestamp
    updates.append("updated_at = :now")

    # Build and execute SQL - safe because all field names come from FIELD_MAPPING
    sql = "UPDATE hero_carousel SET " + ", ".join(updates) + " WHERE id = :id"

    with mysql_engine.begin() as conn:
        result = conn.execute(text(sql), params)

        if result.rowcount == 0:
            return jsonify({"success": False, "error": "åœ–ç‰‡ä¸å­˜åœ¨"}), 404

        log_admin_action('update', 'hero_image', image_id, {'updates': list(data.keys())})

    return jsonify({"success": True, "message": "å·²æ›´æ–°"})


def ensure_chat_session(session_id: Optional[str] = None, member_id: Optional[int] = None) -> str:
    """Return an existing chat session id or create a new one."""
    chat_session_id = session_id or uuid.uuid4().hex
    now = utcnow()
    with mysql_engine.begin() as conn:
        conn.execute(
            text(
                """
                INSERT INTO chat_sessions (id, member_id, created_at, updated_at)
                VALUES (:id, :member_id, :now, :now)
                ON DUPLICATE KEY UPDATE updated_at = :now
                """
            ),
            {"id": chat_session_id, "member_id": member_id, "now": now},
        )
    return chat_session_id


def save_chat_message(session_id: str, role: str, content: str, template_id: Optional[str] = None) -> None:
    """Persist a chat message for a given session."""
    with mysql_engine.begin() as conn:
        conn.execute(
            text(
                """
                INSERT INTO chat_messages (session_id, role, content, template_id, created_at)
                VALUES (:sid, :role, :content, :template_id, :created_at)
                """
            ),
            {
                "sid": session_id,
                "role": role,
                "content": content,
                "template_id": template_id,
                "created_at": utcnow(),
            },
        )
        conn.execute(
            text(
                """
                UPDATE chat_sessions
                SET updated_at = :updated_at
                WHERE id = :sid
                """
            ),
            {"sid": session_id, "updated_at": utcnow()},
        )


def fetch_chat_history(session_id: str, limit: int = 12) -> List[Dict[str, Any]]:
    """Fetch the most recent chat history for the session in chronological order."""
    # Strict validation to prevent SQL injection
    if not isinstance(limit, int):
        raise ValueError("limit must be an integer")
    if limit <= 0:
        limit = 1
    if limit > 100:  # Maximum safety limit
        limit = 100

    # Safe to use in query after validation
    query = text(
        f"""
        SELECT role, content
        FROM chat_messages
        WHERE session_id = :sid
        ORDER BY created_at DESC
        LIMIT {int(limit)}
        """
    )

    with mysql_engine.begin() as conn:
        rows = conn.execute(query, {"sid": session_id}).mappings().all()

    # Reverse to chronological order
    return [dict(row) for row in reversed(rows)]


def build_chat_history(history: Iterable[Dict[str, str]]) -> List[Dict[str, str]]:
    """Prepare chat history for OpenAI API (without system/user prompts - handled by RAG)."""
    messages: List[Dict[str, str]] = []
    for item in history:
        role = item.get("role")
        content = (item.get("content") or "").strip()
        if role in {"user", "assistant"} and content:
            messages.append({"role": role, "content": content})
    return messages


def format_sse(payload: Dict[str, Any]) -> str:
    """Serialize a Python dictionary into a Server-Sent Events data frame."""
    return f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"


# Regex pattern to remove OpenAI file search citation markers (e.g., fileciteturn0file5turn0file12)
_CITATION_PATTERN = re.compile(r"fileciteturn\d+file\d+(?:turn\d+file\d+)*")

# Pre-compiled emoji pattern: matches emoji ranges while preserving CJK characters (U+2E80-U+9FFF)
_EMOJI_PATTERN = re.compile(
    "["
    "\U0001F600-\U0001F64F"  # emoticons
    "\U0001F300-\U0001F5FF"  # symbols & pictographs
    "\U0001F680-\U0001F6FF"  # transport & map
    "\U0001F1E0-\U0001F1FF"  # flags
    "\U0001F900-\U0001F9FF"  # supplemental symbols
    "\U0001FA00-\U0001FA6F"  # chess symbols
    "\U0001FA70-\U0001FAFF"  # symbols extended-A
    "\U0000FE00-\U0000FE0F"  # variation selectors
    "\U0000200D"             # zero width joiner
    "\U00002B50"             # star
    "\U000024C2-\U000024FF"  # enclosed alphanumerics (narrow)
    "\U00002702-\U000027B0"  # dingbats
    "\U00002600-\U000026FF"  # misc symbols
    "]+",
    flags=re.UNICODE,
)

_MULTI_SPACE_PATTERN = re.compile(r'  +')


def strip_citations(text: str) -> str:
    """Remove OpenAI file search citation markers from text."""
    return _CITATION_PATTERN.sub("", text)


def _strip_emojis(text: str) -> str:
    """ç§»é™¤æ–‡å­—ä¸­çš„ emoji å’Œè¡¨æƒ…ç¬¦è™Ÿï¼Œä¿ç•™ä¸­æ–‡å­—å…ƒ"""
    result = _EMOJI_PATTERN.sub("", text)
    return _MULTI_SPACE_PATTERN.sub(" ", result).strip()


def fix_activity_list_format(text: str) -> str:
    """
    ä¿®æ­£æ´»å‹•åˆ—è¡¨æ ¼å¼ï¼Œç¢ºä¿ç·¨è™Ÿå’Œæ´»å‹•åç¨±åœ¨åŒä¸€è¡Œã€‚

    è™•ç†ä»¥ä¸‹æƒ…æ³ï¼š
    1. ç·¨è™Ÿå’Œæ´»å‹•åç¨±åˆ†è¡Œ â†’ åˆä½µåˆ°åŒä¸€è¡Œ
    2. ç§»é™¤ä¸å¿…è¦çš„ç²—é«”æ¨™è¨˜ï¼ˆæ–°æ ¼å¼ä¸ä½¿ç”¨ç²—é«”ï¼‰
    3. ç§»é™¤æ´»å‹•åç¨±ä¸­çš„ emoji
    """
    lines = text.split('\n')
    result_lines = []
    i = 0

    while i < len(lines):
        line = lines[i].strip()

        # æ¨¡å¼ 1ï¼šç·¨è™Ÿç¨ä½”ä¸€è¡Œï¼ˆå¯èƒ½å¸¶ç²—é«”æˆ–ã€Œæ´»å‹•åç¨±ï¼šã€ï¼‰
        # åŒ¹é…ï¼š1. æˆ– **1.** æˆ– 1. æ´»å‹•åç¨±ï¼šï¼ˆå¾Œé¢æ²’æœ‰å¯¦éš›æ¨™é¡Œï¼‰
        number_only = re.match(r'^(?:\*\*)?(\d+)\.(?:\*\*)?\s*(?:æ´»å‹•åç¨±ï¼š)?\s*$', line)
        if number_only and i + 1 < len(lines):
            number = number_only.group(1)
            next_line = lines[i + 1].strip()
            # ç§»é™¤ä¸‹ä¸€è¡Œçš„ç²—é«”æ¨™è¨˜å’Œã€Œæ´»å‹•åç¨±ï¼šã€å‰ç¶´
            next_line = re.sub(r'^\*\*|\*\*$', '', next_line).strip()
            next_line = re.sub(r'^æ´»å‹•åç¨±[ï¼š:]', '', next_line).strip()
            next_line = _strip_emojis(next_line)
            if next_line:
                result_lines.append(f'{number}. æ´»å‹•åç¨±ï¼š{next_line}')
                i += 2
                continue

        # æ¨¡å¼ 2ï¼šæœ‰ç·¨è™Ÿ+æ¨™é¡Œä½†ä½¿ç”¨ç²—é«”æ ¼å¼ â†’ ç§»é™¤ç²—é«”ï¼Œæ”¹ç‚ºæ–°æ ¼å¼
        # **1. æ¨™é¡Œ** æˆ– **1. æ´»å‹•åç¨±ï¼šæ¨™é¡Œ**
        bold_pattern = re.match(r'^\*\*(\d+)\.\s*(?:æ´»å‹•åç¨±[ï¼š:])?\s*(.+?)\*\*$', line)
        if bold_pattern:
            number = bold_pattern.group(1)
            title = _strip_emojis(bold_pattern.group(2).strip())
            result_lines.append(f'{number}. æ´»å‹•åç¨±ï¼š{title}')
            i += 1
            continue

        # æ¨¡å¼ 3ï¼šæœ‰ç·¨è™Ÿ+æ¨™é¡Œä½†æ²’æœ‰ã€Œæ´»å‹•åç¨±ï¼šã€å‰ç¶´
        # 1. é’å¹´å‰µæ¥­è¬›åº§ï¼ˆä¸å¸¶ç²—é«”ï¼‰
        plain_pattern = re.match(r'^(\d+)\.\s+(?!æ´»å‹•[åæ—¥]|å ±å|è²¼æ–‡)(.+)$', line)
        if plain_pattern:
            number = plain_pattern.group(1)
            title = plain_pattern.group(2).strip()
            title = re.sub(r'^\*\*|\*\*$', '', title).strip()
            title = _strip_emojis(title)
            result_lines.append(f'{number}. æ´»å‹•åç¨±ï¼š{title}')
            i += 1
            continue

        # æ¨¡å¼ 4ï¼šå·²æœ‰ã€Œæ´»å‹•åç¨±ï¼šã€æ ¼å¼ä½†å«æœ‰ emoji
        name_pattern = re.match(r'^(\d+)\.\s*æ´»å‹•åç¨±[ï¼š:]\s*(.+)$', line)
        if name_pattern:
            number = name_pattern.group(1)
            title = _strip_emojis(name_pattern.group(2).strip())
            result_lines.append(f'{number}. æ´»å‹•åç¨±ï¼š{title}')
            i += 1
            continue

        # å…¶ä»–è¡Œä¿æŒä¸è®Š
        result_lines.append(lines[i])
        i += 1

    return '\n'.join(result_lines)


@app.post("/api/chat")
@app.post("/chat")
@csrf_protect
@validate_message_input
@limiter.limit("30 per minute")
def api_chat():
    if not request.is_json:
        return jsonify({"error": "Payload must be JSON."}), 400

    payload = request.get_json(force=True) or {}
    message = (payload.get("message") or "").strip()
    requested_session = payload.get("session_id")
    template_id = payload.get("template_id")  # Extract template_id from payload

    if not message:
        return jsonify({"error": "message is required"}), 400

    # Get logged-in user's member_id from session
    member_id = session.get("user", {}).get("member_id")

    session_id = ensure_chat_session(
        requested_session if isinstance(requested_session, str) else None,
        member_id=member_id
    )
    history = fetch_chat_history(session_id)

    # Persist the user's message before streaming.
    save_chat_message(session_id, "user", message, template_id)

    client = OPENAI_CLIENT
    rag_store = get_rag_store_name()

    def generate():
        logger.info("Streaming response for session %s", session_id)
        yield format_sse({"type": "session", "content": "", "session_id": session_id})

        if client is None or rag_store is None:
            assistant_text = (
                "ç„¡æ³•é€£æ¥ OpenAI æœå‹™ã€‚è«‹æª¢æŸ¥ä¼ºæœå™¨è¨­å®šã€‚\n\n"
                f"å¾…ç™¼é€è¨Šæ¯ï¼š{message}\n"
                "è«‹ç¢ºèª OPENAI_API_KEY å·²è¨­å®šå¾Œå†è©¦ã€‚"
            )
            save_chat_message(session_id, "assistant", assistant_text)
            yield format_sse(
                {"type": "text", "content": assistant_text, "session_id": session_id}
            )
            yield format_sse({"type": "end", "content": "", "session_id": session_id})
            return

        accumulated: List[str] = []
        sources: List[Dict[str, Any]] = []

        try:
            chat_history = build_chat_history(history)

            for chunk in generate_with_rag_stream(
                query=message,
                system_prompt=SYSTEM_PROMPT,
                chat_history=chat_history,
                model=OPENAI_MODEL
            ):
                if chunk["type"] == "text":
                    delta = chunk["content"]
                    if delta:
                        # Remove citation markers before sending to client
                        clean_delta = strip_citations(delta)
                        accumulated.append(clean_delta)
                        if clean_delta:
                            yield format_sse(
                                {
                                    "type": "text",
                                    "content": clean_delta,
                                    "session_id": session_id,
                                }
                            )
                elif chunk["type"] == "sources":
                    sources = chunk["content"]
                elif chunk["type"] == "end":
                    pass

        except Exception as e:
            from openai import RateLimitError, APITimeoutError, OpenAIError
            from sqlalchemy.exc import SQLAlchemyError

            error_message = "ç”¢ç”Ÿå›è¦†æ™‚ç™¼ç”Ÿå•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦æˆ–è¯ç¹«æˆ‘å€‘çš„æœå‹™äººå“¡ã€‚"

            if isinstance(e, RateLimitError):
                logger.warning(f"OpenAI rate limit hit for session {session_id}")
                error_message = "æœå‹™æš«æ™‚éè¼‰ï¼Œè«‹ç¨å¾Œé‡è©¦"
            elif isinstance(e, APITimeoutError):
                logger.warning(f"OpenAI timeout for session {session_id}")
                error_message = "AI æœå‹™éŸ¿æ‡‰è¶…æ™‚ï¼Œè«‹é‡è©¦"
            elif isinstance(e, OpenAIError):
                logger.error(f"OpenAI API error: {e}", exc_info=True)
                error_message = "AI æœå‹™æš«æ™‚ä¸å¯ç”¨"
            elif isinstance(e, SQLAlchemyError):
                logger.error(f"Database error in chat: {e}", exc_info=True)
                error_message = "æ•¸æ“šåº«éŒ¯èª¤ï¼Œè«‹é‡è©¦"
            elif isinstance(e, ValueError):
                logger.warning(f"Invalid input: {e}")
                error_message = str(e)
            else:
                logger.critical(f"Unexpected error in chat: {e}", exc_info=True)

            save_chat_message(session_id, "assistant", error_message)
            yield format_sse(
                {"type": "error", "content": error_message, "session_id": session_id}
            )
            yield format_sse({"type": "end", "content": "", "session_id": session_id})
            return

        full_text = "".join(accumulated).strip()

        # ä¿®æ­£æ´»å‹•åˆ—è¡¨æ ¼å¼ï¼ˆç¢ºä¿ç·¨è™Ÿå’Œæ¨™é¡Œåœ¨åŒä¸€è¡Œä¸”ä½¿ç”¨ç²—é«”ï¼‰
        if full_text:
            full_text = fix_activity_list_format(full_text)
            save_chat_message(session_id, "assistant", full_text)
        else:
            fallback_text = "æŠ±æ­‰ï¼Œæˆ‘ç›®å‰ç„¡æ³•å›è¦†ã€‚è«‹é‡æ–°æè¿°æ‚¨çš„å•é¡Œæˆ–è¯ç¹«æˆ‘å€‘çš„æœå‹™äººå“¡ã€‚"
            full_text = fallback_text
            save_chat_message(session_id, "assistant", fallback_text)
            yield format_sse(
                {"type": "text", "content": fallback_text, "session_id": session_id}
            )

        # Yield sources if available
        if sources:
            yield format_sse(
                {"type": "sources", "content": sources, "session_id": session_id}
            )

        # é€å‡ºæ ¼å¼åŒ–å¾Œçš„å®Œæ•´æ–‡å­—ï¼Œè®“å‰ç«¯æ›¿æ›ä¸²æµç´¯ç©çš„æœªæ ¼å¼åŒ–ç‰ˆæœ¬
        yield format_sse({"type": "end", "content": full_text, "session_id": session_id})

    response = Response(
        stream_with_context(generate()),
        mimetype="text/event-stream",
    )
    response.headers["Cache-Control"] = "no-cache"
    response.headers["X-Accel-Buffering"] = "no"
    return response


def fetchall(sql: str, params: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
    with mysql_engine.begin() as conn:
        return [
            dict(row)
            for row in conn.execute(text(sql), params or {}).mappings().all()
        ]


def fetchone(sql: str, params: Optional[Dict[str, Any]] = None) -> Optional[Dict[str, Any]]:
    with mysql_engine.begin() as conn:
        result = conn.execute(text(sql), params or {}).mappings().first()
        return dict(result) if result else None


def execute(sql: str, params: Optional[Dict[str, Any]] = None) -> None:
    with mysql_engine.begin() as conn:
        conn.execute(text(sql), params or {})


def _clean(value: Optional[str]) -> Optional[str]:
    if value is None:
        return None
    trimmed = str(value).strip()
    return trimmed or None


def upsert_member(
    external_id: Optional[str],
    display_name: Optional[str] = None,
    avatar_url: Optional[str] = None,
    gender: Optional[str] = None,
    birthday: Optional[str] = None,
    email: Optional[str] = None,
    phone: Optional[str] = None,
    source: Optional[str] = "form",
) -> Optional[int]:
    """Create or update a member record identified by an external id."""
    external_id = _clean(external_id)
    if not external_id:
        return None

    now = utcnow()
    data = {
        "display_name": _clean(display_name),
        "avatar_url": _clean(avatar_url),
        "gender": _clean(gender),
        "birthday": _clean(birthday),
        "email": _clean(email),
        "phone": _clean(phone),
        "source": source or "form",
        "updated_at": now,
        "last_interaction_at": now,
    }

    with mysql_engine.begin() as conn:
        existing = conn.execute(
            text("SELECT id FROM members WHERE external_id = :ext"),
            {"ext": external_id},
        ).scalar()
        if existing:
            conn.execute(
                text(
                    """
                    UPDATE members
                       SET display_name=:display_name,
                           avatar_url=:avatar_url,
                           gender=:gender,
                           birthday=:birthday,
                           email=:email,
                           phone=:phone,
                           source=:source,
                           updated_at=:updated_at,
                           last_interaction_at=:last_interaction_at
                     WHERE id=:member_id
                    """
                ),
                {**data, "member_id": existing},
            )
            return int(existing)

        insert_params = {
            "external_id": external_id,
            **data,
            "created_at": now,
        }
        result = conn.execute(
            text(
                """
                INSERT INTO members (
                    external_id,
                    display_name,
                    avatar_url,
                    gender,
                    birthday,
                    email,
                    phone,
                    source,
                    created_at,
                    updated_at,
                    last_interaction_at
                ) VALUES (
                    :external_id,
                    :display_name,
                    :avatar_url,
                    :gender,
                    :birthday,
                    :email,
                    :phone,
                    :source,
                    :created_at,
                    :updated_at,
                    :last_interaction_at
                )
                """
            ),
            insert_params,
        )
        member_id = result.lastrowid
    return int(member_id) if member_id is not None else None



# Survey-related functions and templates removed



@app.get("/")
def index():
    """Serve the index.html file from dist directory in production, or BASE_DIR in development"""
    # ä¼˜å…ˆä» dist ç›®å½•æä¾›ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ï¼Œå¦åˆ™ä» BASE_DIRï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    dist_index = os.path.join(DIST_DIR, "index.html")
    if os.path.exists(dist_index):
        return send_from_directory(DIST_DIR, "index.html")
    return send_from_directory(BASE_DIR, "index.html")


@app.route("/<path:path>")
def serve_static(path: str):
    """Serve static files from dist directory"""
    # æ£€æŸ¥æ˜¯å¦æ˜¯ API è·¯ç”±ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
    if path.startswith("api/") or path.startswith("__"):
        abort(404)
    
    # ä¼˜å…ˆä» dist ç›®å½•æä¾›é™æ€æ–‡ä»¶
    dist_path = os.path.join(DIST_DIR, path)
    if os.path.exists(dist_path) and os.path.isfile(dist_path):
        return send_from_directory(DIST_DIR, path)
    
    # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å› index.htmlï¼ˆç”¨äº SPA è·¯ç”±ï¼‰
    dist_index = os.path.join(DIST_DIR, "index.html")
    if os.path.exists(dist_index):
        return send_from_directory(DIST_DIR, "index.html")
    
    abort(404)


@app.get("/health")
def health() -> tuple[Dict[str, Any], int]:
    """Health check endpoint with database connection test."""
    health_status: Dict[str, Any] = {
        "status": "healthy",
        "database": "unknown",
        "timestamp": datetime.datetime.now(timezone.utc).isoformat(),
    }

    try:
        with mysql_engine.connect() as conn:
            conn.execute(text("SELECT 1"))
            conn.commit()
        health_status["database"] = "connected"
    except Exception as e:
        logger.error("Health check failed: MySQL connection error: %s", e)
        health_status["status"] = "unhealthy"
        health_status["database"] = "disconnected"
        health_status["error"] = str(e)
        return health_status, 503

    return health_status, 200


# ==================== OAuth Routes ====================

@app.get("/auth/config")
def api_auth_config():
    """Return OAuth configuration for frontend (without secrets)."""
    return jsonify({
        "google": {
            "enabled": bool(GOOGLE_CLIENT_ID),
            "client_id": GOOGLE_CLIENT_ID,
            "redirect_uri": GOOGLE_REDIRECT_URI
        },
        "line": {
            "enabled": bool(LINE_CHANNEL_ID),
            "channel_id": LINE_CHANNEL_ID,
            "redirect_uri": LINE_REDIRECT_URI
        },
        "facebook": {
            "enabled": bool(FACEBOOK_APP_ID),
            "app_id": FACEBOOK_APP_ID,
            "redirect_uri": FACEBOOK_REDIRECT_URI
        }
    })


# OAuth state configuration
OAUTH_VALID_PROVIDERS = {"google", "line", "facebook"}
OAUTH_STATE_EXPIRY_SECONDS = 900  # 15 minutes


@app.post("/api/auth/state/<provider>")
def generate_oauth_state(provider: str):
    """Generate and store a cryptographically secure OAuth state parameter.

    The state parameter prevents CSRF attacks during OAuth flows by ensuring
    the callback request originated from this application.

    Args:
        provider: OAuth provider name (google, line, or facebook)

    Returns:
        JSON response containing the generated state token
    """
    if provider not in OAUTH_VALID_PROVIDERS:
        return jsonify({"error": "Invalid provider"}), 400

    state = secrets.token_urlsafe(32)
    session_key = f"oauth_state_{provider}"

    session[session_key] = {
        "state": state,
        "created_at": utcnow().isoformat()
    }
    session.permanent = False  # Temporary session for OAuth flow

    logger.info(f"Generated OAuth state for provider: {provider}")
    return jsonify({"state": state})


def validate_oauth_state(provider: str, received_state: Optional[str]) -> bool:
    """Validate OAuth state parameter to prevent CSRF attacks.

    Performs three security checks:
    1. State parameter presence and match (constant-time comparison)
    2. Expiration check (must be within OAUTH_STATE_EXPIRY_SECONDS)
    3. One-time use (state is cleared after successful validation)

    Args:
        provider: OAuth provider name (google, line, or facebook)
        received_state: State parameter from the OAuth callback

    Returns:
        True if state is valid and not expired, False otherwise
    """
    if not received_state:
        logger.warning(f"OAuth callback missing state parameter: {provider}")
        return False

    session_key = f"oauth_state_{provider}"
    stored_data = session.get(session_key)

    if not stored_data:
        logger.warning(f"No stored state found for provider: {provider}")
        return False

    stored_state = stored_data.get("state")
    created_at_str = stored_data.get("created_at")

    # Security: Use constant-time comparison to prevent timing attacks
    if not secrets.compare_digest(received_state, stored_state):
        logger.warning(f"OAuth state mismatch for provider: {provider}")
        return False

    # Validate expiration timestamp
    if not created_at_str:
        logger.error(f"Missing created_at timestamp for provider: {provider}")
        return False

    try:
        created_at = datetime.datetime.fromisoformat(created_at_str)
        # Make timezone-aware for comparison (utcnow returns naive UTC datetime)
        if created_at.tzinfo is None:
            created_at = created_at.replace(tzinfo=datetime.timezone.utc)
        age_seconds = (datetime.datetime.now(datetime.timezone.utc) - created_at).total_seconds()

        if age_seconds > OAUTH_STATE_EXPIRY_SECONDS:
            logger.warning(f"OAuth state expired for provider: {provider} (age: {age_seconds:.0f}s)")
            return False
    except (ValueError, TypeError) as e:
        logger.error(f"Invalid created_at timestamp for provider: {provider}, error: {e}")
        return False

    # Security: Clear state after validation (one-time use prevents replay attacks)
    session.pop(session_key, None)

    logger.info(f"OAuth state validated successfully for provider: {provider}")
    return True


@app.get("/auth/google/callback")
def auth_google_callback():
    """Handle Google OAuth callback."""
    code = request.args.get("code")
    error = request.args.get("error")
    state = request.args.get("state")

    # Validate state parameter to prevent CSRF attacks
    if not validate_oauth_state("google", state):
        logger.error("Google OAuth: Invalid or missing state parameter")
        return redirect("/?error=oauth_csrf_validation_failed")

    if error:
        logger.error(f"Google OAuth error: {error}")
        return redirect("/?error=google_auth_failed")

    if not code:
        return redirect("/?error=no_code")

    try:
        # Exchange code for token
        token_response = http_requests.post(
            "https://oauth2.googleapis.com/token",
            data={
                "code": code,
                "client_id": GOOGLE_CLIENT_ID,
                "client_secret": GOOGLE_CLIENT_SECRET,
                "redirect_uri": GOOGLE_REDIRECT_URI,
                "grant_type": "authorization_code"
            }
        )
        token_data = token_response.json()
        access_token = token_data.get("access_token")

        if not access_token:
            logger.error(f"Google token exchange failed: {token_data}")
            return redirect("/?error=google_token_exchange_failed")

        # Get user info
        user_response = http_requests.get(
            "https://www.googleapis.com/oauth2/v2/userinfo",
            headers={"Authorization": f"Bearer {access_token}"}
        )
        user_info = user_response.json()

        # Upsert member and store in session
        member_id = upsert_member(
            external_id=f"google_{user_info['id']}",
            display_name=user_info.get("name"),
            avatar_url=user_info.get("picture"),
            email=user_info.get("email"),
            source="google"
        )

        # Regenerate session ID to prevent session fixation attack
        session.clear()
        session.modified = True

        session["user"] = {
            "member_id": member_id,
            "provider": "google",
            "external_id": f"google_{user_info['id']}",
            "email": user_info.get("email"),
            "name": user_info.get("name")
        }
        session.permanent = True

        return redirect("/?login=success")

    except Exception as e:
        logger.exception("Google OAuth token exchange failed")
        return redirect("/?error=google_token_exchange_failed")


@app.get("/auth/line/callback")
def auth_line_callback():
    """Handle LINE OAuth callback."""
    code = request.args.get("code")
    error = request.args.get("error")
    state = request.args.get("state")

    # Validate state parameter to prevent CSRF attacks
    if not validate_oauth_state("line", state):
        logger.error("LINE OAuth: Invalid or missing state parameter")
        return redirect("/?error=oauth_csrf_validation_failed")

    if error:
        logger.error(f"LINE OAuth error: {error}")
        return redirect("/?error=line_auth_failed")

    if not code:
        return redirect("/?error=no_code")

    try:
        # Exchange code for token (LINE requires form-urlencoded)
        token_response = http_requests.post(
            "https://api.line.me/oauth2/v2.1/token",
            data={
                "grant_type": "authorization_code",
                "code": code,
                "redirect_uri": LINE_REDIRECT_URI,
                "client_id": LINE_CHANNEL_ID,
                "client_secret": LINE_CHANNEL_SECRET
            },
            headers={"Content-Type": "application/x-www-form-urlencoded"}
        )
        token_data = token_response.json()
        access_token = token_data.get("access_token")

        if not access_token:
            logger.error(f"LINE token exchange failed: {token_data}")
            return redirect("/?error=line_token_exchange_failed")

        # Get user profile
        profile_response = http_requests.get(
            "https://api.line.me/v2/profile",
            headers={"Authorization": f"Bearer {access_token}"}
        )
        profile = profile_response.json()

        # Upsert member and store in session
        member_id = upsert_member(
            external_id=f"line_{profile['userId']}",
            display_name=profile.get("displayName"),
            avatar_url=profile.get("pictureUrl"),
            source="line"
        )

        # Regenerate session ID to prevent session fixation attack
        session.clear()
        session.modified = True

        session["user"] = {
            "member_id": member_id,
            "provider": "line",
            "external_id": f"line_{profile['userId']}",
            "name": profile.get("displayName")
        }
        session.permanent = True

        logger.info(f"[LINE Login] User logged in: {profile.get('displayName')} (member_id: {member_id}, external_id: line_{profile['userId']})")

        return redirect("/?login=success")

    except Exception as e:
        logger.exception("LINE OAuth token exchange failed")
        return redirect("/?error=line_token_exchange_failed")


@app.get("/auth/facebook/callback")
def auth_facebook_callback():
    """Handle Facebook OAuth callback."""
    code = request.args.get("code")
    error = request.args.get("error")
    state = request.args.get("state")

    # Validate state parameter to prevent CSRF attacks
    if not validate_oauth_state("facebook", state):
        logger.error("Facebook OAuth: Invalid or missing state parameter")
        return redirect("/?error=oauth_csrf_validation_failed")

    if error:
        logger.error(f"Facebook OAuth error: {error}")
        return redirect("/?error=facebook_auth_failed")

    if not code:
        return redirect("/?error=no_code")

    try:
        # Exchange code for token
        token_response = http_requests.get(
            "https://graph.facebook.com/v18.0/oauth/access_token",
            params={
                "client_id": FACEBOOK_APP_ID,
                "client_secret": FACEBOOK_APP_SECRET,
                "redirect_uri": FACEBOOK_REDIRECT_URI,
                "code": code
            }
        )
        token_data = token_response.json()
        access_token = token_data.get("access_token")

        if not access_token:
            logger.error(f"Facebook token exchange failed: {token_data}")
            return redirect("/?error=facebook_token_exchange_failed")

        # Get user profile
        profile_response = http_requests.get(
            "https://graph.facebook.com/me",
            params={
                "fields": "id,name,email,picture.type(large)",
                "access_token": access_token
            }
        )
        profile = profile_response.json()

        picture_url = None
        if profile.get("picture") and profile["picture"].get("data"):
            picture_url = profile["picture"]["data"].get("url")

        # Upsert member and store in session
        member_id = upsert_member(
            external_id=f"facebook_{profile['id']}",
            display_name=profile.get("name"),
            avatar_url=picture_url,
            email=profile.get("email"),
            source="facebook"
        )

        # Regenerate session ID to prevent session fixation attack
        session.clear()
        session.modified = True

        session["user"] = {
            "member_id": member_id,
            "provider": "facebook",
            "external_id": f"facebook_{profile['id']}",
            "email": profile.get("email"),
            "name": profile.get("name")
        }
        session.permanent = True

        return redirect("/?login=success")

    except Exception as e:
        logger.exception("Facebook OAuth token exchange failed")
        return redirect("/?error=facebook_token_exchange_failed")


@app.get("/api/user")
def api_get_user():
    """Return current authenticated user or guest status.

    Returns 200 with success=false for unauthenticated users to avoid
    console warnings while maintaining clear authentication state.
    """
    # Debug: è¨˜éŒ„ session è³‡è¨Š
    from flask import request as flask_request
    logger.info(f"[/api/user] Session ID cookie: {flask_request.cookies.get('session', 'N/A')[:20] if flask_request.cookies.get('session') else 'None'}...")
    logger.info(f"[/api/user] Session data: {dict(session) if session else 'Empty'}")
    if "user" in session:
        user_data = session["user"].copy()
        # å¾è³‡æ–™åº«è®€å–é ­åƒ (é¿å… session cookie éå¤§å°è‡´ 431 éŒ¯èª¤)
        if user_data.get("member_id"):
            member = fetchone(
                "SELECT avatar_url FROM members WHERE id = :id",
                {"id": user_data["member_id"]}
            )
            if member:
                user_data["picture"] = member.get("avatar_url")
        response = jsonify({
            "success": True,
            "user": user_data
        })
        return _no_store(response)
    # Return 200 with success=false for unauthenticated users
    # This avoids console warnings while clearly indicating no user is logged in
    response = jsonify({
        "success": False,
        "message": "Not authenticated"
    })
    return _no_store(response)


@app.post("/api/logout")
def api_logout():
    """Destroy session and logout user."""
    session.clear()
    return jsonify({
        "success": True,
        "message": "Logged out successfully"
    })


@app.get(f"{ASSET_ROUTE_PREFIX}/<path:filename>")
def serve_uploads(filename: str):
    return send_from_directory(ASSET_LOCAL_DIR, filename, conditional=True)



if __name__ == "__main__":
    port = int(os.getenv("PORT", "8300"))
    debug_mode = os.getenv("FLASK_DEBUG", "0") in {"1", "true", "True"}
    app.run(host="0.0.0.0", port=port, debug=debug_mode)
