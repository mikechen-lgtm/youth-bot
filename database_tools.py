"""
è³‡æ–™åº«æŸ¥è©¢å·¥å…·æ¨¡çµ„ - æä¾›æ´»å‹•è³‡æ–™æŸ¥è©¢åŠŸèƒ½ä¾› AI èª¿ç”¨

æ­¤æ¨¡çµ„å¯¦ç¾ OpenAI Function Calling å·¥å…·ï¼Œç”¨æ–¼å¾ MySQL è³‡æ–™è¡¨æŸ¥è©¢æ´»å‹•è³‡æ–™ã€‚
ä½¿ç”¨å°åŒ—æ™‚å€ (Asia/Taipei) ç¢ºä¿æ™‚é–“è¨ˆç®—æº–ç¢ºæ€§ã€‚
"""
from __future__ import annotations

import json
import logging
import os
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from zoneinfo import ZoneInfo

logger = logging.getLogger(__name__)

# å°åŒ—æ™‚å€
TAIPEI_TZ = ZoneInfo("Asia/Taipei")

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()


def _build_mysql_url() -> str:
    """å»ºç«‹ MySQL é€£æ¥ URL"""
    if os.getenv("MYSQL_URL"):
        return os.getenv("MYSQL_URL")

    host = os.getenv("MYSQL_HOST", "localhost")
    port = os.getenv("MYSQL_PORT", "3306")
    user = os.getenv("MYSQL_USER", "root")
    password = os.getenv("MYSQL_PASSWORD", "")
    database = os.getenv("MYSQL_DATABASE", "youth-chat")
    return f"mysql+pymysql://{user}:{password}@{host}:{port}/{database}"


_engine: Optional[Engine] = None


def _get_engine() -> Engine:
    """å–å¾—å…¨åŸŸ SQLAlchemy engineï¼ˆsingletonï¼‰"""
    global _engine
    if _engine is None:
        mysql_url = _build_mysql_url()
        _engine = create_engine(
            mysql_url,
            pool_pre_ping=True,
            pool_size=5,
            max_overflow=10,
            pool_recycle=3600,
            connect_args={"charset": "utf8mb4"},
        )
    return _engine


def _today_start() -> datetime:
    """å–å¾—ä»Šå¤© 00:00ï¼ˆå°åŒ—æ™‚å€ï¼‰ï¼Œä½œç‚ºéå»/æœªä¾†æ´»å‹•çš„åˆ†ç•Œé»"""
    now = datetime.now(TAIPEI_TZ)
    return now.replace(hour=0, minute=0, second=0, microsecond=0)


def _format_activity_result(row) -> Dict[str, Any]:
    """æ ¼å¼åŒ–å–®ç­†æ´»å‹•è³‡æ–™"""
    # å„ªå…ˆä½¿ç”¨ event_dateï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨ publish_date
    effective_date = row[4] if row[4] else row[3]

    return {
        "source": row[0],
        "title": row[1],
        "content": row[2][:500] + "..." if row[2] and len(row[2]) > 500 else row[2],
        "publish_date": effective_date.strftime("%Y/%m/%d %H:%M") if effective_date else None,
        "url": row[5],
        "tags": json.loads(row[6]) if row[6] else [],
    }


def get_past_activities(days_back: int = 30, limit: int = 20) -> Dict[str, Any]:
    """
    ç²å–éå»çš„æ´»å‹•ï¼ˆç™¼å¸ƒæ™‚é–“åœ¨ä»Šå¤©ä¹‹å‰ï¼‰

    Args:
        days_back: å¾€å‰æŸ¥è©¢çš„å¤©æ•¸ï¼ˆé è¨­ 30 å¤©ï¼‰
        limit: æœ€å¤šè¿”å›å¹¾ç­†ï¼ˆé è¨­ 20 ç­†ï¼‰

    Returns:
        åŒ…å«æ´»å‹•åˆ—è¡¨ã€çµ±è¨ˆè³‡è¨Šçš„å­—å…¸
    """
    try:
        engine = _get_engine()
        today = _today_start()
        start_date = today - timedelta(days=days_back)

        query = text("""
            SELECT
                source,
                title,
                content,
                publish_date,
                event_date,
                url,
                tags
            FROM fb_activities
            WHERE COALESCE(event_date, publish_date) < :today_start
              AND COALESCE(event_date, publish_date) >= :start_date
            ORDER BY COALESCE(event_date, publish_date) DESC
            LIMIT :limit
        """)

        with engine.begin() as conn:
            result = conn.execute(
                query,
                {
                    "today_start": today,
                    "start_date": start_date,
                    "limit": limit,
                }
            )
            rows = result.fetchall()

        activities = [_format_activity_result(row) for row in rows]

        return {
            "success": True,
            "query_type": "past_activities",
            "time_range": {
                "from": start_date.strftime("%Y/%m/%d"),
                "to": today.strftime("%Y/%m/%d"),
                "description": f"{start_date.strftime('%Y/%m/%d')} åˆ° {today.strftime('%Y/%m/%d')}ï¼ˆéå» {days_back} å¤©ï¼‰"
            },
            "total_count": len(activities),
            "activities": activities,
        }

    except Exception as e:
        logger.error("æŸ¥è©¢éå»æ´»å‹•å¤±æ•—: %s", e)
        return {
            "success": False,
            "error": str(e),
            "query_type": "past_activities",
        }


def get_recent_activities(days_ahead: int = 90, limit: int = 20) -> Dict[str, Any]:
    """
    ç²å–è¿‘æœŸæ´»å‹•ï¼ˆç™¼å¸ƒæ™‚é–“åœ¨ä»Šå¤©åˆ°æœªä¾† N å¤©å…§ï¼‰

    Args:
        days_ahead: å¾€å¾ŒæŸ¥è©¢çš„å¤©æ•¸ï¼ˆé è¨­ 90 å¤©ï¼Œç´„ 3 å€‹æœˆï¼‰
        limit: æœ€å¤šè¿”å›å¹¾ç­†ï¼ˆé è¨­ 20 ç­†ï¼‰

    Returns:
        åŒ…å«æ´»å‹•åˆ—è¡¨ã€çµ±è¨ˆè³‡è¨Šçš„å­—å…¸
    """
    try:
        engine = _get_engine()
        today = _today_start()
        end_date = today + timedelta(days=days_ahead)

        query = text("""
            SELECT
                source,
                title,
                content,
                publish_date,
                event_date,
                url,
                tags
            FROM fb_activities
            WHERE COALESCE(event_date, publish_date) >= :today_start
              AND COALESCE(event_date, publish_date) <= :end_date
            ORDER BY COALESCE(event_date, publish_date) ASC
            LIMIT :limit
        """)

        with engine.begin() as conn:
            result = conn.execute(
                query,
                {
                    "today_start": today,
                    "end_date": end_date,
                    "limit": limit,
                }
            )
            rows = result.fetchall()

        activities = [_format_activity_result(row) for row in rows]

        return {
            "success": True,
            "query_type": "recent_activities",
            "time_range": {
                "from": today.strftime("%Y/%m/%d"),
                "to": end_date.strftime("%Y/%m/%d"),
                "description": f"{today.strftime('%Y/%m/%d')} åˆ° {end_date.strftime('%Y/%m/%d')}ï¼ˆæœªä¾† {days_ahead} å¤©ï¼‰"
            },
            "total_count": len(activities),
            "activities": activities,
        }

    except Exception as e:
        logger.error("æŸ¥è©¢è¿‘æœŸæ´»å‹•å¤±æ•—: %s", e)
        return {
            "success": False,
            "error": str(e),
            "query_type": "recent_activities",
        }


def execute_database_tool(function_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
    """
    çµ±ä¸€çš„è³‡æ–™åº«å·¥å…·åŸ·è¡Œä»‹é¢

    Args:
        function_name: å·¥å…·å‡½æ•¸åç¨±
        arguments: å‡½æ•¸åƒæ•¸å­—å…¸

    Returns:
        å‡½æ•¸åŸ·è¡Œçµæœæˆ–éŒ¯èª¤è³‡è¨Š
    """
    tool_map = {
        "get_past_activities": lambda: get_past_activities(**arguments),
        "get_recent_activities": lambda: get_recent_activities(**arguments),
    }

    if function_name not in tool_map:
        return {
            "success": False,
            "error": f"æœªçŸ¥çš„å·¥å…·å‡½æ•¸: {function_name}",
            "function_name": function_name,
            "arguments": arguments,
        }

    try:
        result = tool_map[function_name]()
        logger.info("åŸ·è¡Œè³‡æ–™åº«å·¥å…·æˆåŠŸ: %s", function_name)
        return result
    except Exception as e:
        logger.error("åŸ·è¡Œè³‡æ–™åº«å·¥å…·å¤±æ•—: %s, éŒ¯èª¤: %s", function_name, e)
        return {
            "success": False,
            "error": str(e),
            "function_name": function_name,
            "arguments": arguments,
        }


# OpenAI Function Calling å·¥å…·å®šç¾©
DATABASE_TOOLS_DEFINITIONS = [
    {
        "type": "function",
        "function": {
            "name": "get_past_activities",
            "description": (
                "æŸ¥è©¢éå»çš„æ´»å‹•ï¼ˆæ´»å‹•æ—¥æœŸåœ¨ä»Šå¤©ä¹‹å‰ï¼‰ã€‚"
                "ç”¨æ–¼å›ç­”ã€Œéå»æœ‰ä»€éº¼æ´»å‹•ã€ã€Œä¹‹å‰è¾¦éä»€éº¼ã€ç­‰å•é¡Œã€‚"
                "å„ªå…ˆä½¿ç”¨æ´»å‹•æ—¥æœŸï¼ˆevent_dateï¼‰ï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨ç™¼å¸ƒæ—¥æœŸï¼ˆpublish_dateï¼‰ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "days_back": {
                        "type": "integer",
                        "description": "å¾€å‰æŸ¥è©¢çš„å¤©æ•¸ï¼Œä¾‹å¦‚ 30 è¡¨ç¤ºéå» 30 å¤©",
                        "default": 30,
                    },
                    "limit": {
                        "type": "integer",
                        "description": "æœ€å¤šè¿”å›å¹¾ç­†æ´»å‹•",
                        "default": 20,
                    },
                },
                "required": [],
            },
        },
    },
    {
        "type": "function",
        "function": {
            "name": "get_recent_activities",
            "description": (
                "æŸ¥è©¢è¿‘æœŸæ´»å‹•ï¼ˆæ´»å‹•æ—¥æœŸåœ¨ä»Šå¤©åˆ°æœªä¾† N å¤©å…§ï¼‰ã€‚"
                "ç”¨æ–¼å›ç­”ã€Œæœ€è¿‘æœ‰ä»€éº¼æ´»å‹•ã€ã€Œè¿‘æœŸæ´»å‹•ã€ã€Œæ¥ä¸‹ä¾†æœ‰ä»€éº¼ã€ç­‰å•é¡Œã€‚"
                "ğŸ”´ é‡è¦ï¼šé€™æ˜¯æŸ¥è©¢ã€Œæœªä¾†æ´»å‹•ã€çš„ä¸»è¦å·¥å…·ï¼Œç•¶ç”¨æˆ¶å•è¿‘æœŸ/æœ€è¿‘æ´»å‹•æ™‚å¿…é ˆä½¿ç”¨ã€‚"
                "å„ªå…ˆä½¿ç”¨æ´»å‹•æ—¥æœŸï¼ˆevent_dateï¼‰ï¼Œè‹¥ç„¡å‰‡ä½¿ç”¨ç™¼å¸ƒæ—¥æœŸï¼ˆpublish_dateï¼‰ã€‚"
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "days_ahead": {
                        "type": "integer",
                        "description": "å¾€å¾ŒæŸ¥è©¢çš„å¤©æ•¸ï¼Œä¾‹å¦‚ 90 è¡¨ç¤ºæœªä¾† 3 å€‹æœˆ",
                        "default": 90,
                    },
                    "limit": {
                        "type": "integer",
                        "description": "æœ€å¤šè¿”å›å¹¾ç­†æ´»å‹•",
                        "default": 20,
                    },
                },
                "required": [],
            },
        },
    },
]

__all__ = [
    "get_past_activities",
    "get_recent_activities",
    "execute_database_tool",
    "DATABASE_TOOLS_DEFINITIONS",
]
