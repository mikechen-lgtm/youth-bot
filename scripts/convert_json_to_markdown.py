"""
å°‡ RAG è³‡æ–™å¤¾ä¸­çš„ JSON æª”æ¡ˆè½‰æ›ç‚º Markdown æ ¼å¼
æŒ‰æ´»å‹•æ—¥æœŸè‡ªå‹•åˆ†é¡ç‚ºã€Œéå»æ´»å‹•ã€å’Œã€Œè¿‘æœŸæ´»å‹•ã€

ç‰ˆæœ¬ v3.0:
- æ”¶é›†æ‰€æœ‰ JSON æª”æ¡ˆçš„æ´»å‹•
- æŒ‰æ´»å‹•æ—¥æœŸéæ¿¾åˆ†é¡
- åªç”Ÿæˆå…©å€‹æª”æ¡ˆï¼šéå»æ´»å‹•.mdã€è¿‘æœŸæ´»å‹•.md
"""
from __future__ import annotations

import argparse
import json
import re
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Tuple, List

from zoneinfo import ZoneInfo

TAIPEI_TZ = ZoneInfo("Asia/Taipei")

# æ—¥æœŸè§£ææ­£å‰‡è¡¨é”å¼
DATE_PATTERNS = {
    "iso": re.compile(r'(\d{4})[/-](\d{1,2})[/-](\d{1,2})'),
    "roc": re.compile(r'(\d{3})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥'),
    "month_day": re.compile(r'(\d{1,2})æœˆ(\d{1,2})æ—¥'),
}


def format_date(date_str: str) -> str:
    """å°‡ ISO æ—¥æœŸæ ¼å¼è½‰æ›ç‚º yyyy/mm/dd æ ¼å¼"""
    if not date_str:
        return ""
    try:
        if "T" in date_str:
            dt = datetime.fromisoformat(date_str.replace("Z", "+00:00"))
            return dt.strftime("%Y/%m/%d %H:%M")
        return date_str
    except (ValueError, TypeError):
        return date_str


def _try_parse_date(year: int, month: int, day: int) -> Optional[datetime]:
    """å˜—è©¦å‰µå»º datetime ç‰©ä»¶ï¼Œå¤±æ•—è¿”å› None"""
    try:
        return datetime(year, month, day, tzinfo=TAIPEI_TZ)
    except ValueError:
        return None


def extract_event_date_from_content(content: str, publish_date: str = None) -> Tuple[Optional[datetime], str]:
    """
    å¾å…§å®¹ä¸­æå–æ´»å‹•æ—¥æœŸ

    Returns:
        (event_datetime, event_date_source)
    """
    if not content:
        return None, ""

    # ISO æ ¼å¼: YYYY/MM/DD æˆ– YYYY-MM-DD
    match = DATE_PATTERNS["iso"].search(content)
    if match:
        year, month, day = map(int, match.groups())
        date = _try_parse_date(year, month, day)
        if date:
            return date, "extracted_from_content"

    # æ°‘åœ‹å¹´: 115å¹´1æœˆ23æ—¥
    match = DATE_PATTERNS["roc"].search(content)
    if match:
        roc_year, month, day = map(int, match.groups())
        date = _try_parse_date(roc_year + 1911, month, day)
        if date:
            return date, "extracted_from_content"

    # æœˆæ—¥: 1æœˆ24æ—¥ï¼ˆæ¨æ–·å¹´ä»½ï¼‰
    match = DATE_PATTERNS["month_day"].search(content)
    if match:
        month, day = map(int, match.groups())
        now = datetime.now(TAIPEI_TZ)

        date = _try_parse_date(now.year, month, day)
        if date:
            # å¦‚æœæ—¥æœŸå·²éä¸”æœ‰ publish_dateï¼Œä½¿ç”¨æ˜å¹´
            if publish_date and date < now:
                next_year_date = _try_parse_date(now.year + 1, month, day)
                if next_year_date:
                    return next_year_date, "inferred_from_content"
            return date, "inferred_from_content"

    return None, ""


def extract_post_content(post: dict) -> str:
    """å¾è²¼æ–‡è³‡æ–™æå–ä¸»è¦å…§å®¹"""
    return (post.get("content") or post.get("raw_content") or "").strip()


def get_event_date(post: dict) -> Optional[datetime]:
    """
    æå–è²¼æ–‡çš„æ´»å‹•æ—¥æœŸ

    Returns:
        æ´»å‹•æ—¥æœŸçš„ datetime ç‰©ä»¶ï¼Œå¦‚æœç„¡æ³•æå–å‰‡è¿”å› None
    """
    # å„ªå…ˆä½¿ç”¨çµæ§‹åŒ–çš„æ´»å‹•æ™‚é–“
    time_data = post.get("time", {})
    if isinstance(time_data, dict):
        event_time = time_data.get("event")
    else:
        event_time = post.get("event_time")

    if event_time:
        try:
            if "T" in event_time:
                return datetime.fromisoformat(event_time.replace("Z", "+00:00")).replace(tzinfo=TAIPEI_TZ)
            # å˜—è©¦è§£æ YYYY/MM/DD æˆ– YYYY-MM-DD æ ¼å¼
            for fmt in ["%Y/%m/%d", "%Y-%m-%d"]:
                try:
                    return datetime.strptime(event_time.split()[0], fmt).replace(tzinfo=TAIPEI_TZ)
                except ValueError:
                    continue
        except (ValueError, TypeError):
            pass

    # å¾å…§å®¹æå–æ—¥æœŸ
    content = extract_post_content(post)
    publish_date = post.get("publish_date")
    event_datetime, _ = extract_event_date_from_content(content, publish_date)
    return event_datetime


def _format_location(location) -> Optional[str]:
    """æ ¼å¼åŒ–åœ°é»è³‡è¨Š"""
    if not location:
        return None

    if isinstance(location, dict):
        loc_name = location.get("name", "")
        loc_addr = location.get("address", "")
        if loc_name or loc_addr:
            return f"{loc_name}" + (f"ï¼ˆ{loc_addr}ï¼‰" if loc_addr else "")
    elif isinstance(location, str) and location:
        return location

    return None


def _format_links(links: dict) -> list:
    """æ ¼å¼åŒ–é€£çµå€å¡Š"""
    if not links or not isinstance(links, dict):
        return []

    valid_links = {k: v for k, v in links.items() if v}
    if not valid_links:
        return []

    link_names = {
        "registration": "å ±åé€£çµ",
        "info": "è©³ç´°è³‡è¨Š",
        "apply": "ç·šä¸Šç”³è«‹",
        "url": "åŸæ–‡é€£çµ",
    }

    lines = ["## ç›¸é—œé€£çµ"]
    for key, url in valid_links.items():
        name = link_names.get(key, key)
        lines.append(f"- {name}ï¼š{url}")
    lines.append("")

    return lines


def format_post_to_markdown(post: dict, source: str, event_date: datetime) -> str:
    """å°‡å–®ä¸€è²¼æ–‡è½‰æ›ç‚º Markdown æ ¼å¼"""
    lines = []

    # æ¨™é¡Œ
    title = post.get("title", "ç„¡æ¨™é¡Œæ´»å‹•")
    lines.extend([f"# {title}", ""])

    # å…ƒæ•¸æ“šå€å¡Š
    publish_date = post.get("publish_date")
    if publish_date:
        lines.append(f"**ç™¼å¸ƒæ—¥æœŸï¼š** {format_date(publish_date)}")

    # æ´»å‹•æ—¥æœŸ
    lines.append(f"**æ´»å‹•æ—¥æœŸï¼š** {event_date.strftime('%Y/%m/%d')}")

    # ä¾†æº
    lines.append(f"**ä¾†æºï¼š** {source}")
    lines.extend(["", "---", ""])

    # è©³ç´°æ™‚é–“è³‡è¨Š
    time_data = post.get("time", {})
    event_time = time_data.get("event") if isinstance(time_data, dict) else post.get("event_time")
    if event_time:
        lines.append(f"**æ´»å‹•æ™‚é–“ï¼š** {format_date(event_time)}")

    deadline = time_data.get("deadline") if isinstance(time_data, dict) else post.get("deadline")
    if deadline:
        lines.append(f"**å ±åæˆªæ­¢ï¼š** {format_date(deadline)}")

    # åœ°é»è³‡è¨Š
    location_str = _format_location(post.get("location"))
    if location_str:
        lines.append(f"**åœ°é»ï¼š** {location_str}")

    # é©ç”¨å°è±¡
    target = post.get("target")
    if target:
        lines.append(f"**é©ç”¨å°è±¡ï¼š** {target}")

    # è£œåŠ©é‡‘é¡
    subsidy = post.get("subsidy")
    if subsidy and isinstance(subsidy, dict):
        subsidy_str = ", ".join(f"{k}ï¼š{v}" for k, v in subsidy.items())
        lines.append(f"**è£œåŠ©é‡‘é¡ï¼š** {subsidy_str}")

    lines.append("")

    # ä¸»è¦å…§å®¹
    content = extract_post_content(post)
    if content:
        lines.extend(["## å…§å®¹", "", content, ""])

    # èšç„¦é ˜åŸŸ
    focus_areas = post.get("focus_areas")
    if focus_areas:
        lines.append("## èšç„¦é ˜åŸŸ")
        lines.extend(f"- {area}" for area in focus_areas)
        lines.append("")

    # ææ¡ˆé¡åˆ¥
    categories = post.get("categories")
    if categories:
        lines.append("## ææ¡ˆé¡åˆ¥")
        lines.extend(f"- {cat}" for cat in categories)
        lines.append("")

    # ç›¸é—œé€£çµ
    lines.extend(_format_links(post.get("links")))

    # åŸæ–‡é€£çµ
    url = post.get("url")
    if url:
        lines.extend([f"**åŸæ–‡é€£çµï¼š** {url}", ""])

    # æ¨™ç±¤
    tags = post.get("tags")
    if tags:
        lines.extend([f"**æ¨™ç±¤ï¼š** {', '.join(tags)}", ""])

    return "\n".join(lines)


def collect_all_posts(rag_dir: Path) -> List[Tuple[dict, str, Optional[datetime]]]:
    """
    æ”¶é›†æ‰€æœ‰ JSON æª”æ¡ˆä¸­çš„æ´»å‹•

    Returns:
        List of (post, source, event_date)
    """
    all_posts = []
    json_files = list(rag_dir.glob("*.json"))

    print(f"ğŸ“‚ æ‰¾åˆ° {len(json_files)} å€‹ JSON æª”æ¡ˆ")

    for json_path in json_files:
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            if "posts" not in data:
                print(f"  â­ï¸  è·³é {json_path.name}ï¼ˆä¸åŒ…å« postsï¼‰")
                continue

            source = data.get("source", json_path.stem)
            posts = data.get("posts", [])

            for post in posts:
                event_date = get_event_date(post)
                if event_date:
                    all_posts.append((post, source, event_date))
                    print(f"  âœ“ {source}: {post.get('title', 'ç„¡æ¨™é¡Œ')[:30]} - {event_date.strftime('%Y/%m/%d')}")
                else:
                    print(f"  âš ï¸  ç„¡æ³•æå–æ—¥æœŸ: {post.get('title', 'ç„¡æ¨™é¡Œ')[:30]}")

        except json.JSONDecodeError as e:
            print(f"  âŒ JSON è§£æéŒ¯èª¤ {json_path.name}: {e}")
        except Exception as e:
            print(f"  âŒ è™•ç†éŒ¯èª¤ {json_path.name}: {e}")

    return all_posts


def generate_categorized_markdown(rag_dir: Path, output_dir: Path) -> Tuple[Path, Path]:
    """
    ç”ŸæˆæŒ‰æ™‚é–“åˆ†é¡çš„ Markdown æª”æ¡ˆ

    Returns:
        (éå»æ´»å‹•æª”æ¡ˆè·¯å¾‘, è¿‘æœŸæ´»å‹•æª”æ¡ˆè·¯å¾‘)
    """
    # æ”¶é›†æ‰€æœ‰æ´»å‹•
    all_posts = collect_all_posts(rag_dir)

    if not all_posts:
        print("\nâš ï¸  æœªæ‰¾åˆ°ä»»ä½•åŒ…å«æ—¥æœŸçš„æ´»å‹•")
        return None, None

    # è¨ˆç®—æ™‚é–“ç¯„åœ
    now = datetime.now(TAIPEI_TZ).replace(hour=0, minute=0, second=0, microsecond=0)
    three_months_later = now + timedelta(days=90)

    # åˆ†é¡æ´»å‹•
    past_posts = []
    upcoming_posts = []

    for post, source, event_date in all_posts:
        if event_date < now:
            past_posts.append((post, source, event_date))
        elif event_date <= three_months_later:
            upcoming_posts.append((post, source, event_date))

    print(f"\nğŸ“Š åˆ†é¡çµæœï¼š")
    print(f"  éå»æ´»å‹•ï¼š{len(past_posts)} å€‹")
    print(f"  è¿‘æœŸæ´»å‹•ï¼ˆä»Šå¤©åˆ°æœªä¾†3å€‹æœˆï¼‰ï¼š{len(upcoming_posts)} å€‹")

    # æ’åºï¼šéå»æ´»å‹•æŒ‰æ—¥æœŸé™åºï¼Œè¿‘æœŸæ´»å‹•æŒ‰æ—¥æœŸå‡åº
    past_posts.sort(key=lambda x: x[2], reverse=True)
    upcoming_posts.sort(key=lambda x: x[2])

    output_dir.mkdir(exist_ok=True)

    # ç”Ÿæˆã€Œéå»æ´»å‹•.mdã€
    past_file = output_dir / "éå»æ´»å‹•.md"
    if past_posts:
        lines = [
            "# æ¡ƒåœ’å¸‚æ”¿åºœé’å¹´äº‹å‹™å±€ - éå»æ´»å‹•",
            "",
            f"**è³‡æ–™æ›´æ–°æ™‚é–“ï¼š** {now.strftime('%Y/%m/%d %H:%M')}",
            f"**æ´»å‹•æ•¸é‡ï¼š** {len(past_posts)} å€‹",
            "",
            "---",
            ""
        ]

        for post, source, event_date in past_posts:
            lines.extend([
                format_post_to_markdown(post, source, event_date),
                "---",
                ""
            ])

        with open(past_file, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

        print(f"\nâœ… å·²ç”Ÿæˆï¼š{past_file}")
    else:
        print(f"\nâ­ï¸  ç„¡éå»æ´»å‹•ï¼Œè·³éç”Ÿæˆ {past_file}")

    # ç”Ÿæˆã€Œè¿‘æœŸæ´»å‹•.mdã€
    upcoming_file = output_dir / "è¿‘æœŸæ´»å‹•.md"
    if upcoming_posts:
        lines = [
            "# æ¡ƒåœ’å¸‚æ”¿åºœé’å¹´äº‹å‹™å±€ - è¿‘æœŸæ´»å‹•",
            "",
            f"**è³‡æ–™æ›´æ–°æ™‚é–“ï¼š** {now.strftime('%Y/%m/%d %H:%M')}",
            f"**æ´»å‹•æ•¸é‡ï¼š** {len(upcoming_posts)} å€‹",
            f"**æ™‚é–“ç¯„åœï¼š** {now.strftime('%Y/%m/%d')} ~ {three_months_later.strftime('%Y/%m/%d')}ï¼ˆæœªä¾†3å€‹æœˆï¼‰",
            "",
            "---",
            ""
        ]

        for post, source, event_date in upcoming_posts:
            days_until = (event_date - now).days
            if days_until == 0:
                time_desc = "**ğŸ”¥ ä»Šå¤©èˆ‰è¾¦ï¼**"
            elif days_until <= 7:
                time_desc = f"**â° æœ¬é€±æ´»å‹•ï¼ˆé‚„æœ‰ {days_until} å¤©ï¼‰**"
            else:
                time_desc = f"é‚„æœ‰ {days_until} å¤©"

            lines.extend([
                format_post_to_markdown(post, source, event_date),
                time_desc,
                "",
                "---",
                ""
            ])

        with open(upcoming_file, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))

        print(f"âœ… å·²ç”Ÿæˆï¼š{upcoming_file}")
    else:
        print(f"\nâ­ï¸  ç„¡è¿‘æœŸæ´»å‹•ï¼Œè·³éç”Ÿæˆ {upcoming_file}")

    return past_file if past_posts else None, upcoming_file if upcoming_posts else None


def main() -> int:
    parser = argparse.ArgumentParser(
        description="å°‡ JSON è²¼æ–‡è³‡æ–™æŒ‰æ™‚é–“åˆ†é¡è½‰æ›ç‚º Markdownï¼ˆéå»æ´»å‹•ã€è¿‘æœŸæ´»å‹•ï¼‰"
    )
    parser.add_argument(
        "--rag-dir",
        default="rag_data",
        help="RAG è³‡æ–™ç›®éŒ„ (é è¨­: rag_data)",
    )
    parser.add_argument(
        "--output-dir",
        help="è¼¸å‡ºç›®éŒ„ (é è¨­: rag_data)",
    )

    args = parser.parse_args()

    rag_dir = Path(args.rag_dir)
    if not rag_dir.exists():
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° RAG ç›®éŒ„ï¼š{rag_dir}")
        return 1

    output_dir = Path(args.output_dir) if args.output_dir else rag_dir

    print(f"\nğŸš€ é–‹å§‹è™•ç†...")
    print(f"   è¼¸å…¥ç›®éŒ„ï¼š{rag_dir}")
    print(f"   è¼¸å‡ºç›®éŒ„ï¼š{output_dir}\n")

    past_file, upcoming_file = generate_categorized_markdown(rag_dir, output_dir)

    if past_file or upcoming_file:
        print(f"\nâœ¨ å®Œæˆï¼æª”æ¡ˆå·²å„²å­˜è‡³ {output_dir}")
        return 0
    else:
        print(f"\nâš ï¸  æœªç”Ÿæˆä»»ä½•æª”æ¡ˆ")
        return 1


if __name__ == "__main__":
    sys.exit(main())
